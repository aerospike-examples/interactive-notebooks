{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Local-Cache\" data-toc-modified-id=\"Local-Cache-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Local Cache</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Prerequisites\" data-toc-modified-id=\"Prerequisites-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Prerequisites</a></span></li><li><span><a href=\"#Initialization\" data-toc-modified-id=\"Initialization-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Initialization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ensure-database-is-running\" data-toc-modified-id=\"Ensure-database-is-running-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Ensure database is running</a></span></li><li><span><a href=\"#Connect-to-database.\" data-toc-modified-id=\"Connect-to-database.-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Connect to database.</a></span></li><li><span><a href=\"#Populate-database-with-test-data.\" data-toc-modified-id=\"Populate-database-with-test-data.-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Populate database with test data.</a></span></li></ul></li></ul></li><li><span><a href=\"#Cache-Design\" data-toc-modified-id=\"Cache-Design-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Cache Design</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cache-Interface\" data-toc-modified-id=\"Cache-Interface-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Cache Interface</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cache-Eviction\" data-toc-modified-id=\"Cache-Eviction-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Cache Eviction</a></span></li><li><span><a href=\"#Working-with-Aerospike-TTL\" data-toc-modified-id=\"Working-with-Aerospike-TTL-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Working with Aerospike TTL</a></span></li></ul></li><li><span><a href=\"#Comparing-Performance\" data-toc-modified-id=\"Comparing-Performance-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Comparing Performance</a></span><ul class=\"toc-item\"><li><span><a href=\"#Effective-Local-Cache-Scenarios\" data-toc-modified-id=\"Effective-Local-Cache-Scenarios-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Effective Local Cache Scenarios</a></span></li></ul></li></ul></li><li><span><a href=\"#Cache-Performance-Model\" data-toc-modified-id=\"Cache-Performance-Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Cache Performance Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Speedup-Formula\" data-toc-modified-id=\"Speedup-Formula-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Speedup Formula</a></span></li></ul></li><li><span><a href=\"#Takeaways\" data-toc-modified-id=\"Takeaways-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Takeaways</a></span></li><li><span><a href=\"#Clean-up\" data-toc-modified-id=\"Clean-up-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Clean up</a></span></li><li><span><a href=\"#Further-Exploration-and-Resources\" data-toc-modified-id=\"Further-Exploration-and-Resources-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Further Exploration and Resources</a></span><ul class=\"toc-item\"><li><span><a href=\"#Next-steps\" data-toc-modified-id=\"Next-steps-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Next steps</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Cache\n",
    "This notebook describes the pattern where a local in-memory cache is used in front of the Aerospike database. It shows with a simple model how a local in-memory cache can enhance performance for specific hit ratio and cache speed scenarios.\n",
    "\n",
    "This notebook requires Aerospike datbase running on localhost and that python and the Aerospike python client have been installed (`pip install aerospike`). Visit [Aerospike notebooks repo](https://github.com/aerospike-examples/interactive-notebooks) for additional details and the docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Caches are ubiquitous. Aerospike is commonly and effectively deployed as a cache in front of a backend database that is remote, slow, and/or limited in throughput. This notebook illustrates use of a local cache on the client machine that sits in front of the Aerospike database, with specific scenarios when it can be beneficial. The pattern is applicable for a standalone Aerospike database as well as when Aerospike itself acts as a cache.\n",
    "\n",
    "A cache provides faster access and improved throughput by having a copy of the data closer to where it is processed. Cache libraries, external caching servers, and distributed cache infrastructure are deployed for specific caching needs and solutions. Aerospike CacheDB is designed for fast, reliable, consistent, and cost-effective access across the globally distributed data infrastructure.\n",
    "\n",
    "The notebook first illustrates a local in-memory cache fronting the Aerospike database through a simple interface, and then analyses the performance impact of a cache in various scenarios through a simple mathematical model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "This tutorial assumes familiarity with the following topics:\n",
    "\n",
    "- Familiarity with Aerospike and API. See [Hello World](hello_world.ipynb)\n",
    "- Basic CRUD operations. See [Aerospike Basic Operations](basic_operations.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure database is running\n",
    "This notebook requires that Aerospike datbase is running. \n",
    "[Include the right code cell for Java or Python from the two cells below.] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T18:28:57.038395Z",
     "start_time": "2021-01-12T18:28:56.755437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aerospike database is running!\r\n"
     ]
    }
   ],
   "source": [
    "!asd >& /dev/null\n",
    "!pgrep -x asd >/dev/null && echo \"Aerospike database is running!\" || echo \"**Aerospike database is not running!**\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to database.\n",
    "We need a client connected to the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T20:48:51.190060Z",
     "start_time": "2020-12-29T20:48:51.110597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client successfully connected to the database.\n"
     ]
    }
   ],
   "source": [
    "# import the module\n",
    "from __future__ import print_function\n",
    "import aerospike\n",
    "\n",
    "# Configure the client\n",
    "config = {\n",
    "  'hosts': [ ('127.0.0.1', 3000) ],\n",
    "  'policy' : {'key': aerospike.POLICY_KEY_SEND}\n",
    "}\n",
    "\n",
    "# Create a client and connect it to the cluster\n",
    "try:\n",
    "  client = aerospike.client(config).connect()\n",
    "except:\n",
    "  import sys\n",
    "  print(\"failed to connect to the cluster with\", config['hosts'])\n",
    "  sys.exit(1)\n",
    "print('Client successfully connected to the database.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate database with test data.\n",
    "The following code populates the test data in set \"local_cache_tutorial\" in namespace \"test\". The data consists of a 10000 records with user keys 1-10000 and bins populated with random data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T20:48:52.195181Z",
     "start_time": "2020-12-29T20:48:52.189787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data populated.\n"
     ]
    }
   ],
   "source": [
    "namespace = 'test'\n",
    "tutorial_set = 'local_cache_tutorial'\n",
    "max_data_size = 10000\n",
    "# Records are addressable via a tuple of (namespace, set, key)\n",
    "\n",
    "import random\n",
    "random.seed(1)\n",
    "try:\n",
    "    for i in range(max_data_size):\n",
    "      # Write the records\n",
    "      client.put((namespace, tutorial_set, 'id-'+str(i+1)), \n",
    "                 { 'age': random.randint(20,81),\n",
    "                   'birth_month': random.choice(['Jan','Feb','Mar','Apr','May','Jun',\n",
    "                                               'Jul','Aug','Sep','Oct','Nov','Dec']),\n",
    "                   'gender': random.choice(['M', 'F']),\n",
    "                   'favorite_colors': random.sample(['red','orange','yellow','green',\n",
    "                                                   'blue','violet','black','white','grey'], k=3) } )\n",
    "except Exception as e:\n",
    "  import sys\n",
    "  print(\"error: {0}\".format(e), file=sys.stderr)\n",
    "\n",
    "print('Test data populated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache Design\n",
    "\n",
    "We will illustrate a local cache fronting the Aerospike database. The key benefit of a local cache stems from its proximity hence speed advantage: Aerospike provides average access time of a millisecond or less for 99%+ requests, while local memory cache access can be in microsecond range. Even so, as we will see, limitations of memory size need to be taken into account as do cost consideration since a local cache needs to be implemented at each client host.\n",
    "\n",
    "First, let us define a simple interface for the local cache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache Interface\n",
    "The cache consists of cache entries with the following key operations:\n",
    "- get(key)\n",
    "    - Get from cache if available and TTL is not expired, else retrieve from the database and add to the cache.\n",
    "- update(key, data)\n",
    "    - Update the database by replacing the current record, and also add or replace the cache entry.\n",
    "- add(key, entry)\n",
    "    - If the cache is full, evict appropriate entry and add the cache entry.\n",
    "\n",
    "### Cache Eviction\n",
    "A local cache can be implemented with TTL based garbage collection. Another alternative is to maintain a Least-Recently-Used (LRU) list and remove LRU entry when the cache is full to make room for a new entry. LRU can be implemented by maintaining a doubly linked list of cache entries - below, the classes CacheEntry and LocalCache allude to LRU links, but the implementation is not provided here.\n",
    "\n",
    "A simplistic eviction scheme below for illustrative purpose selects an arbitrary entry for eviction, using dict.popitem(), although better randomized eviction is possible with implementations like [randomdict](https://github.com/robtandy/randomdict). \n",
    "\n",
    "### Working with Aerospike TTL\n",
    "Aerospike has TTL based eviction that allows for: \n",
    "1. No eviction or the record is permanent, \n",
    "1. At record creation a specific TTL is set, \n",
    "1. TTL may be updated any time. \n",
    "\n",
    "Since the TTL can change at origin while the record resides in the local cache, the cache will sync up with the origin at the time of caching. This is no different from if the record is deleted at the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T17:05:39.701891Z",
     "start_time": "2021-01-12T17:05:39.687304Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "DEFAULT_TTL = 3600\n",
    "\n",
    "class CacheEntry:\n",
    "    _key = None\n",
    "    _ttl = 0\n",
    "    _data = None\n",
    "    # LRU not implemented\n",
    "    # _lru_prev = None\n",
    "    # _lru_next = None\n",
    "    \n",
    "    def __init__(self, key, ttl, data):\n",
    "        self._key = key\n",
    "        self._ttl = ttl\n",
    "        self._data = data.copy()\n",
    "        return\n",
    "        \n",
    "    \n",
    "class LocalCache:\n",
    "    _cache = {}   # dict of key->cache_entry\n",
    "    _max_size = 0\n",
    "    # LRU not implemented\n",
    "    # _lru_head = None\n",
    "    # _lru_tail = None\n",
    "\n",
    "    def __init__(self, max_size):\n",
    "        self._max_size = max_size\n",
    "        return\n",
    "\n",
    "    def get(self, key):\n",
    "        entry = self._cache.get(key)\n",
    "        if entry is None or entry._ttl < time.time():\n",
    "            #print(\"a cache miss\", key[2])\n",
    "            # get it from aerospike database\n",
    "            _, meta, bins = client.get(key)\n",
    "            if meta is None:\n",
    "                #print(\"entry expired at origin\", key[2])\n",
    "                if entry:\n",
    "                    self._cache.pop(key)\n",
    "                return None\n",
    "            if entry: # in cache, replace\n",
    "                entry._ttl = time.time()+meta['ttl']\n",
    "                entry._data = bins\n",
    "            else: # not in cache, add\n",
    "                entry = CacheEntry(key, time.time()+meta['ttl'], bins)\n",
    "                self.add(key, entry)\n",
    "        #else:\n",
    "            #print(\"a cache hit\", key[2])\n",
    "        return entry._data.copy()\n",
    "\n",
    "    def add(self, key, entry):\n",
    "        if len(self._cache) == self._max_size:\n",
    "            #print(\"cache full, evicting\")\n",
    "            _ = self._cache.popitem() # remove a \"random\" entry\n",
    "        self._cache[key] = entry\n",
    "        #print(\"added entry\", key[2])\n",
    "        return\n",
    "\n",
    "    def update(self, key, data):\n",
    "        # update aerospike database and extend TTL\n",
    "        meta = {'ttl': DEFAULT_TTL}\n",
    "        policy = {'exists': aerospike.POLICY_EXISTS_REPLACE}\n",
    "        try:\n",
    "            _, meta, _ = client.operate(key, data, meta=meta, policy=policy)\n",
    "        except:\n",
    "              print('failed to udpdate database')\n",
    "              raise\n",
    "        entry = self._cache.get(key)\n",
    "        if entry is None:\n",
    "            entry = CacheEntry(key, time.time()+DEFAULT_TTL, data)\n",
    "            self.add(key, entry)\n",
    "        else:\n",
    "            entry._ttl = time.time()+DEFAULT_TTL\n",
    "            entry._data = rec.copy()\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Performance\n",
    "There are two key factors that in general impact cache performace. \n",
    "1. Hit ratio H or the fraction of the requests served directly from the cache without having to go to the origin server. Hit ratio depends on factors like the cache size, invalidation (update) rate, and access pattern. \n",
    "1. Speed ratio S or how fast the cache access is as compared to the origin server. Or equivalently, the speed gain of a cache hit over a cache miss.\n",
    "\n",
    "Below we run a simple test and compare execution times for \"without cache\" and \"with cache\" scenarios over a large number of requests. (Feel free to experiment with different values of data_size and cache_size to adjust the hit ratio. Speed ratio for this implementation can vary and is unknown.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache hit ratio:  0.40\n",
      "Execution time without cache:  0.637s\n",
      "Execution time with cache:  0.479s\n",
      "Speedup with cache:   33.0%\n"
     ]
    }
   ],
   "source": [
    "data_size = 5000\n",
    "cache_size = 2000\n",
    "print('Cache hit ratio: ', '%3.2f'%(cache_size/data_size))\n",
    "num_requests = 10000\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(num_requests):\n",
    "    user_key = 'id-' + str(random.randint(1, data_size))\n",
    "    key = (namespace, tutorial_set, user_key)\n",
    "    _ = client.get(key)\n",
    "time_without_cache = time.time() - start_time\n",
    "print('Execution time without cache: ', '%5.3fs'%time_without_cache)\n",
    "\n",
    "start_time = time.time()\n",
    "cache = LocalCache(cache_size)\n",
    "for i in range(num_requests):\n",
    "    user_key = 'id-' + str(random.randint(1, data_size))\n",
    "    key = (namespace, tutorial_set, user_key)\n",
    "    _ = cache.get(key)\n",
    "time_with_cache = time.time() - start_time\n",
    "print('Execution time with cache: ', '%5.3fs'%time_with_cache)\n",
    "\n",
    "print('Speedup with cache: ', '%5.1f%%'%((time_without_cache/time_with_cache - 1) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effective Local Cache Scenarios\n",
    "The theoretical performance boost from a cache ranges from 0 (no improvement) when the hit ration (H) is 0 meaning all requests are served from the orgin server, up to the speed ratio (S) when H is 1 meaning all requests are served from the cache.\n",
    "\n",
    "When Aerospike database is used as a cache, it provides performance and throughput gain through: \n",
    "- a robust hit ratio with its ability to scale to petabyte range and mechanisms to keep the cache in sync with the origin. \n",
    "- a huge speed ratio with its sub-millisecond predictable. Speedup over the origin database can range from 100 to 1000 or more.\n",
    "\n",
    "So when can a local cache be beneficial in conjunction with Aerospike? A local cache can be effective if the data for local caching is targeted judiciously in order to keep the hit ratio high in spite of the local cache's size limitations. Thet is, targeting data that is frequently read, infrequently updated, and  performance critical. The benefit will need to be balanced against the cost of deploying it across multiple client machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache Performance Model\n",
    "We use a simple mathematical model to examine the theoretical performance. A simple model is used with two cache parameters, hit ratio and speed ratio, discussed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speedup Formula\n",
    "The following discussion is applicable to both a local cache in front of the Aerospike database, as well as Aerospike Cache in front of a backend database.\n",
    "\n",
    "For N random accesses made directly to the origin database, the time needed is N * T, where T is the average access time for the origin database.\n",
    "\n",
    "With a hit ratio of H and speed ratio of S:\n",
    "- N\\*H requests are directly served from the cache each with T/S access time. The total access time for cache served requests is  N\\*H\\*T/S.\n",
    "- The remaining N\\*(1-H) requests are served from the origin in N\\*(1-H)\\*T time.\n",
    "- The total access time with a cache is the addition of the above two: N\\*H\\*T/S + N\\*(1-H)\\*T.\n",
    "- The speedup in time and throughput is the ratio of total time without a cache to the total time with a cache. That is, N*T / [N\\*H\\*T/S + N\\*(1-H)\\*T] or 1/(1 - H + H/S).\n",
    "\n",
    "Note, as expected, as H approaches 1 (all requests served from the cache), the speedup approaches S, the cache speed ratio, and as H approaches 0, the speedup approaches 0 (no speedup).\n",
    "\n",
    "The following code implements the speedup function with parameters H and S. These are computed below with various H and S values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\tH\tEffective Speedup\n",
      "10\t0.1\t   10%\t*\n",
      "10\t0.3\t   37%\t****\n",
      "10\t0.5\t   82%\t*********\n",
      "10\t0.7\t  170%\t******************\n",
      "10\t0.9\t  426%\t*******************************************\n",
      "100\t0.1\t   11%\t**\n",
      "100\t0.3\t   42%\t*****\n",
      "100\t0.5\t   98%\t**********\n",
      "100\t0.7\t  226%\t***********************\n",
      "100\t0.9\t  817%\t**********************************************************************************\n",
      "1000\t0.1\t   11%\t**\n",
      "1000\t0.3\t   43%\t*****\n",
      "1000\t0.5\t  100%\t**********\n",
      "1000\t0.7\t  233%\t************************\n",
      "1000\t0.9\t  891%\t******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def cache_speedup(hit_ratio, speed_ratio):\n",
    "    return 1.0/(1.0 - hit_ratio + hit_ratio / speed_ratio)\n",
    "\n",
    "hr = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "sr = [10, 100, 1000]\n",
    "print('S', 'H', 'Effective Speedup', sep='\\t')\n",
    "for s in sr:\n",
    "    for h in hr:\n",
    "        print(s, h, '%5.0f%%'%((cache_speedup(h, s)-1)*100), \n",
    "              math.ceil((cache_speedup(h, s)-1)*10)*'*', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, a cache can provide performance and throughput boost in both scenarios:\n",
    "- A local cache fronting the Aerospike database *if a high hit ratio can be attained by targeting right data*.\n",
    "- Aerospike Cache fronting a backend database because Aerospike provides a large cache size (hence hit ratio) and sub-miilisecond access time (hence high speed ratio)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways\n",
    "The key takeaways are:\n",
    "- A local cache can augment performance and throughput of Aerospike database. A local cache can be expensive as it has to be deployed at each client host, but can be effective if high hit ratio is achievable with repeat access to a small subset of data.\n",
    "- Aerospike  provides significant performance and throughput boost over the backend database due to its large cache size and automatic sync mechanisms(which typically transalate into a higher hit ratio), and a sub-millisecond access time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up\n",
    "Remove data and close the server connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T20:49:21.100931Z",
     "start_time": "2020-12-29T20:49:21.095318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed tutorial data. Connection closed.\n"
     ]
    }
   ],
   "source": [
    "client.truncate(namespace, tutorial_set, 0)\n",
    "# Close the connection to the Aerospike cluster\n",
    "client.close()\n",
    "print('Removed tutorial data. Connection closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Exploration and Resources\n",
    "Explore further how Aerospike can be deployed as a cache.\n",
    "- Jupyter Notebook: [A Simple Look-Aside Cache](https://github.com/aerospike/aerospike-dev-notebooks.docker/blob/main/notebooks/python/look_aside_cache.ipynb)\n",
    "- Blog post: [Can you think of an application that can’t benefit from speed?](https://www.aerospike.com/blog/apps-benefit-from-speed/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Visit [Aerospike notebooks repo](https://github.com/aerospike-examples/interactive-notebooks) to run additional Aerospike notebooks. To run a different notebook, download the notebook from the repo to your local machine, and then click on File->Open, and select Upload."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
