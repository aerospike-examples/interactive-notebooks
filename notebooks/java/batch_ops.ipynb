{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Batch-Operations-in-Aerospike\" data-toc-modified-id=\"Batch-Operations-in-Aerospike-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Batch Operations in Aerospike</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Prerequisites\" data-toc-modified-id=\"Prerequisites-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Prerequisites</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ensure-database-is-running\" data-toc-modified-id=\"Ensure-database-is-running-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Ensure database is running</a></span><ul class=\"toc-item\"><li><span><a href=\"#Add-second-namespace-and-restart-database\" data-toc-modified-id=\"Add-second-namespace-and-restart-database-1.3.1.1\"><span class=\"toc-item-num\">1.3.1.1&nbsp;&nbsp;</span>Add second namespace and restart database</a></span></li></ul></li><li><span><a href=\"#Download-and-install-additional-components.\" data-toc-modified-id=\"Download-and-install-additional-components.-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Download and install additional components.</a></span></li><li><span><a href=\"#Initialize-Client\" data-toc-modified-id=\"Initialize-Client-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Initialize Client</a></span></li><li><span><a href=\"#Define-Constants-and-Helper-Functions\" data-toc-modified-id=\"Define-Constants-and-Helper-Functions-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>Define Constants and Helper Functions</a></span></li><li><span><a href=\"#Populate-and-Examine-Test-Data\" data-toc-modified-id=\"Populate-and-Examine-Test-Data-1.3.5\"><span class=\"toc-item-num\">1.3.5&nbsp;&nbsp;</span>Populate and Examine Test Data</a></span></li><li><span><a href=\"#Register-UDF\" data-toc-modified-id=\"Register-UDF-1.3.6\"><span class=\"toc-item-num\">1.3.6&nbsp;&nbsp;</span>Register UDF</a></span></li><li><span><a href=\"#Import-Client-Modules\" data-toc-modified-id=\"Import-Client-Modules-1.3.7\"><span class=\"toc-item-num\">1.3.7&nbsp;&nbsp;</span>Import Client Modules</a></span></li></ul></li></ul></li><li><span><a href=\"#New-Batch-Capabilities\" data-toc-modified-id=\"New-Batch-Capabilities-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>New Batch Capabilities</a></span><ul class=\"toc-item\"><li><span><a href=\"#Multi-key-Operate\" data-toc-modified-id=\"Multi-key-Operate-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Multi-key Operate</a></span></li><li><span><a href=\"#Multi-key-UDF-Execute\" data-toc-modified-id=\"Multi-key-UDF-Execute-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Multi-key UDF Execute</a></span></li><li><span><a href=\"#Multi-key-Delete\" data-toc-modified-id=\"Multi-key-Delete-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Multi-key Delete</a></span></li><li><span><a href=\"#General-Batch-Operate\" data-toc-modified-id=\"General-Batch-Operate-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>General Batch Operate</a></span></li></ul></li><li><span><a href=\"#Related-Topics\" data-toc-modified-id=\"Related-Topics-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Related Topics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-Read-and-Write-Operation-Expressions\" data-toc-modified-id=\"Using-Read-and-Write-Operation-Expressions-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Using Read and Write Operation Expressions</a></span></li><li><span><a href=\"#Using-Filter-Expressions-with-Batch-Processing\" data-toc-modified-id=\"Using-Filter-Expressions-with-Batch-Processing-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Using Filter Expressions with Batch Processing</a></span></li><li><span><a href=\"#Inline-Processing\" data-toc-modified-id=\"Inline-Processing-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Inline Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Another-Example\" data-toc-modified-id=\"Another-Example-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Another Example</a></span></li></ul></li><li><span><a href=\"#Asynchronous-Batch-Processing\" data-toc-modified-id=\"Asynchronous-Batch-Processing-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Asynchronous Batch Processing</a></span></li><li><span><a href=\"#Batch-Reads\" data-toc-modified-id=\"Batch-Reads-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Batch Reads</a></span></li></ul></li><li><span><a href=\"#Takeaways-and-Conclusion\" data-toc-modified-id=\"Takeaways-and-Conclusion-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Takeaways and Conclusion</a></span></li><li><span><a href=\"#Clean-up\" data-toc-modified-id=\"Clean-up-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Clean up</a></span></li><li><span><a href=\"#Further-Exploration-and-Resources\" data-toc-modified-id=\"Further-Exploration-and-Resources-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Further Exploration and Resources</a></span><ul class=\"toc-item\"><li><span><a href=\"#Next-steps\" data-toc-modified-id=\"Next-steps-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Next steps</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Operations in Aerospike\n",
    "This tutorial describes the batch operations in Aerospike.\n",
    "\n",
    "This notebook requires the Aerospike Database running locally with Java kernel and Aerospike Java Client. To create a Docker container that satisfies the requirements and holds a copy of Aerospike notebooks, visit the [Aerospike Notebooks Repo](https://github.com/aerospike-examples/interactive-notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we will describe the batch capabilities in Aerospike. \n",
    "\n",
    "Batch functionality in Aerospike Java Client versions before 6.0 and Aerospike Database versions before 6.0 was supported only for read operations. With the Java Client 6.0+ and Aerospike Database 6.0+ working together, batch executions are expanded to include write, UDF, and delete. The notebook focuses on the newly added capabilities. The older read batch operations are described elsewhere including [here](sql-select.ipynb).\n",
    "\n",
    "The specific topics covered in this notebook include:\n",
    "- New batch functionality\n",
    "- Code examples of the synchronous batch APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "This tutorial assumes familiarity with the following topics:\n",
    "- [Hello World](hello_world.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure database is running\n",
    "This notebook requires that Aerospike database is running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T20:48:49.065421Z",
     "start_time": "2020-12-29T20:48:49.060897Z"
    }
   },
   "outputs": [],
   "source": [
    "import io.github.spencerpark.ijava.IJava;\n",
    "import io.github.spencerpark.jupyter.kernel.magic.common.Shell;\n",
    "IJava.getKernelInstance().getMagics().registerMagics(Shell.class);\n",
    "%sh asd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add second namespace and restart database\n",
    "Open a terminal tab by selecting File->Open from the notebook menu, and then New->Terminal. Run the `add-namespace.sh` script to add a namespace `test2` to the config and restart the server.\n",
    "\n",
    "`\n",
    "~/notebooks/java/add_namespace.sh test2\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and install additional components.\n",
    "Install the Java client version 6.0 or above that supports the new batch capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T20:48:50.084636Z",
     "start_time": "2020-12-29T20:48:50.080629Z"
    }
   },
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<dependencies>\n",
    "  <dependency>\n",
    "    <groupId>com.aerospike</groupId>\n",
    "    <artifactId>aerospike-client</artifactId>\n",
    "    <version>6.0.0</version>\n",
    "  </dependency>\n",
    "</dependencies>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Client\n",
    "Initialize the client. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized the client and connected to the cluster.\n"
     ]
    }
   ],
   "source": [
    "import com.aerospike.client.AerospikeClient;\n",
    "\n",
    "AerospikeClient client = new AerospikeClient(\"localhost\", 3000);\n",
    "System.out.println(\"Initialized the client and connected to the cluster.\");;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Constants and Helper Functions\n",
    "Define constants for the namespaces `test` and `test2`,  sets `batch-ops` and `batch-ops2`, and helper functions `truncateTestData`, `initializeTestData`, and `printRecords`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.aerospike.client.AerospikeException;\n",
    "import com.aerospike.client.Bin;\n",
    "import com.aerospike.client.Key;\n",
    "import com.aerospike.client.policy.WritePolicy;\n",
    "\n",
    "final String Namespace1 = \"test\";\n",
    "final String Namespace2 = \"test2\";\n",
    "final String Set1 = \"batch-ops\";\n",
    "final String Set2 = \"batch-ops2\";\n",
    "final String KeyPrefix = \"id-\";\n",
    "\n",
    "// convenience function to truncate test data\n",
    "void truncateTestData() {\n",
    "    try {\n",
    "        client.truncate(null, Namespace1, null, null);\n",
    "        client.truncate(null, Namespace2, null, null);\n",
    "    }\n",
    "    catch (AerospikeException e) {\n",
    "        // ignore\n",
    "    }\n",
    "}\n",
    "\n",
    "// convenience function to initialize test data\n",
    "void initializeTestData() {\n",
    "    truncateTestData();\n",
    "    WritePolicy wpolicy = new WritePolicy();\n",
    "    wpolicy.sendKey = true;\n",
    "    for (int i = 1; i <= 3; i++) {\n",
    "        for (String ns : Arrays.asList(Namespace1, Namespace2)) {       \n",
    "            for (String set : Arrays.asList(Set1, Set2)) {\n",
    "                Key key = new Key(ns, set, KeyPrefix+i);\n",
    "                Bin bin1 = new Bin(new String(\"bin1\"), i);\n",
    "                Bin bin2 = new Bin(new String(\"bin2\"), 10*i);\n",
    "                HashMap <Integer, Integer> map = new HashMap <Integer, Integer>();\n",
    "                for (int j = 1; j <= i; j++) {\n",
    "                    map.put(j, j*10);\n",
    "                }\n",
    "                Bin bin3 = new Bin(\"bin3\", map);\n",
    "                client.put(wpolicy, key, bin1, bin2, bin3);\n",
    "            }\n",
    "        }        \n",
    "    }\n",
    "}\n",
    "\n",
    "// convenience function to print all records in a namespace and set\n",
    "//   (please note this is not an efficient implementation to scan all records across sets/namespaces.\n",
    "//    refer to set-index and scan documentation for additional pointers on this topic.)\n",
    "import com.aerospike.client.Record;\n",
    "import com.aerospike.client.ScanCallback;\n",
    "import com.aerospike.client.policy.ScanPolicy;\n",
    "\n",
    "public class ScanParallel implements ScanCallback {\n",
    "    public void scanCallback(Key key, Record record) {\n",
    "        System.out.format(\"\\tKey %s: %s\\n\", key.userKey, record.bins);\n",
    "    }\n",
    "}\n",
    "void printRecords() {\n",
    "    System.out.println(\"Records in database:\");\n",
    "    for (String ns : Arrays.asList(Namespace1, Namespace2)) {       \n",
    "        for (String set : Arrays.asList(Set1, Set2)) {\n",
    "            System.out.format(\"Namespace: %s, set: %s: \\n\", ns, set);\n",
    "            client.scanAll(null, ns, set, new ScanParallel());\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate and Examine Test Data\n",
    "Populate and examine the test data. It contains 3 records each in the following 4 sets:\n",
    "- set batch-ops in namespace test\n",
    "- set batch-ops2 in namespace test\n",
    "- set batch-ops in namespace test2\n",
    "- set batch-ops2 in namespace test2\n",
    "\n",
    "Each record has:\n",
    "- user key: a unique sequential number k (1-3) prefixed with \"id-\"\n",
    "- bin1: integer with value of k\n",
    "- bin2: integer with vslue of k * 10\n",
    "- bin3: map holding k keys (1-k) and corresponding values k * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data populated.\n",
      "Records in database:\n",
      "Namespace: test, set: batch-ops: \n",
      "\tKey id-2: {bin1=2, bin2=20, bin3={1=10, 2=20}}\n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-1: {bin1=1, bin2=10, bin3={1=10}}\n",
      "Namespace: test, set: batch-ops2: \n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-1: {bin1=1, bin2=10, bin3={1=10}}\n",
      "\tKey id-2: {bin1=2, bin2=20, bin3={1=10, 2=20}}\n",
      "Namespace: test2, set: batch-ops: \n",
      "\tKey id-1: {bin1=1, bin2=10, bin3={1=10}}\n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-2: {bin1=2, bin2=20, bin3={1=10, 2=20}}\n",
      "Namespace: test2, set: batch-ops2: \n",
      "\tKey id-1: {bin1=1, bin2=10, bin3={1=10}}\n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-2: {bin1=2, bin2=20, bin3={1=10, 2=20}}\n"
     ]
    }
   ],
   "source": [
    "initializeTestData();\n",
    "System.out.format(\"Test data populated.\\n\");;\n",
    "printRecords();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register UDF\n",
    "In the code examples later, we will be using UDF functions in the \"update_example.lua\" module under \"udf\" directory. Register the UDF with the server by executing the following code cell. The function invalidates the cache, removes the currently registered module, and registers the latest version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered the UDF module update_example.lua."
     ]
    }
   ],
   "source": [
    "import com.aerospike.client.policy.Policy;\n",
    "import com.aerospike.client.task.RegisterTask;\n",
    "import com.aerospike.client.Language;\n",
    "import com.aerospike.client.lua.LuaConfig;\n",
    "import com.aerospike.client.lua.LuaCache;\n",
    "\n",
    "LuaConfig.SourceDirectory = \"../udf\";\n",
    "String UDFFile = \"update_example.lua\";\n",
    "String UDFModule = \"update_example\";\n",
    "\n",
    "void registerUDF() {\n",
    "    // clear the lua cache\n",
    "    LuaCache.clearPackages();\n",
    "    Policy policy = new Policy();\n",
    "    // remove the current module, if any\n",
    "    client.removeUdf(null, UDFFile);\n",
    "    RegisterTask task = client.register(policy, LuaConfig.SourceDirectory+\"/\"+UDFFile, \n",
    "                                        UDFFile, Language.LUA);\n",
    "    task.waitTillComplete();\n",
    "    System.out.format(\"Registered the UDF module %s.\", UDFFile);;\n",
    "}\n",
    "\n",
    "registerUDF();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Client Modules\n",
    "Import the Java Client modules used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.aerospike.client.BatchRecord;\n",
    "import com.aerospike.client.BatchResults;\n",
    "import com.aerospike.client.ResultCode;\n",
    "import com.aerospike.client.BatchWrite;\n",
    "import com.aerospike.client.BatchDelete;\n",
    "import com.aerospike.client.BatchUDF;\n",
    "import com.aerospike.client.BatchRead;\n",
    "import com.aerospike.client.policy.BatchPolicy;\n",
    "import com.aerospike.client.policy.BatchDeletePolicy;\n",
    "import com.aerospike.client.Bin;\n",
    "import com.aerospike.client.Key;\n",
    "import com.aerospike.client.Operation;\n",
    "import com.aerospike.client.Record;\n",
    "import com.aerospike.client.Value;\n",
    "import com.aerospike.client.cdt.MapOperation;\n",
    "import com.aerospike.client.cdt.MapPolicy;\n",
    "import com.aerospike.client.cdt.MapReturnType;\n",
    "import com.aerospike.client.cdt.ListReturnType;\n",
    "import com.aerospike.client.exp.Exp;\n",
    "import com.aerospike.client.exp.ListExp;\n",
    "import com.aerospike.client.exp.MapExp;\n",
    "import com.aerospike.client.exp.ExpOperation;\n",
    "import com.aerospike.client.exp.ExpReadFlags;\n",
    "import com.aerospike.client.exp.ExpWriteFlags;\n",
    "import com.aerospike.client.exp.Expression;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Batch Capabilities\n",
    "We will illustrate the following new batch capabilities with code examples below. \n",
    "- Multi-key operate: Performs the same set of operations on multiple records.\n",
    "- Multi-key UDF execute: Executes the same UDF function on multiple records.\n",
    "- Multi-key delete: Deletes multiple records.\n",
    "- General batch operate: Allows a separate list of operations for each record in the batch.\n",
    "\n",
    "A few important things to keep in mind about batch operations:\n",
    "- Transaction semantics. The batch operations are not transactional. The transactional boundary assured is for individual key operations. In the general batch operate function, if the key is specified multiple times, the transaction is limited to each specific occurrence. \n",
    "- Atomicity. A batch is not processed atomically. There is no rollback available for partially successful operations.\n",
    "- Order of execution. Order within a  batch write is not guaranteed  unless “in line” for write is specified. \n",
    "- Maximum batch size. The maximum batch size in a request (sent to a single server node) is defined by the configurable server parameter [batch-max-requests](https://docs.aerospike.com/reference/configuration#batch-max-requests) (default: 5000).\n",
    "\n",
    "In this notebook, we will explore the synchronous version of the APIs. The asychronous versions have the same operation semantics, and can be implemented using the setup instructions in [this notebook](async_ops.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-key Operate\n",
    "`\n",
    "BatchResults operate(BatchPolicy batchPolicy,\n",
    "                    BatchWritePolicy writePolicy,\n",
    "                    Key[] keys,\n",
    "                    Operation... ops)\n",
    "`\n",
    "\n",
    "It allows you to specify a list of keys and a list of operations. In the operations list:\n",
    "- Read and write operations can be mixed.\n",
    "- Read operations must specify individual bins.\n",
    "- Deletes can be specified.\n",
    "- UDF operations cannot be specified.\n",
    "\n",
    "\n",
    "Note in the example below:\n",
    "- BatchResults contains an array of BatchRecords with resultCode, key, and record fields. The record field holds the return values by bin.\n",
    "- Each successful operation always returns a result, which may be a null, for example, for a write operation.\n",
    "- There may be multiple operations on the same bin. Each operation result is stored in the record field in a bin-specific result list. Use getList(binName) or getValue(binName) to get the results list,  0-based \"bin relative\" operation index to retrieve op results, and type cast the value appropriately. See bin2 and bin3 operations in the example below.\n",
    "- For a single occurrence of a bin in operations, the results can be obtained simply using the type-specific get operation. See bin1 operation in the example below.\n",
    "- In case of an error, the resultCode has the error code and the record field is null. \n",
    "- You can peform read batch operations using this new API in 6.0, as well as the existing batch read capabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All batch operations succeeded.\n",
      "Result[0]: key: test/batch-ops/id-1, bin1: 1, bin2: 11, bin3 size: 2, bin3 max val: 10\n",
      "Result[1]: key: test/batch-ops/id-2, bin1: 2, bin2: 21, bin3 size: 3, bin3 max val: 20\n",
      "Result[2]: key: test/batch-ops2/id-1, bin1: 1, bin2: 11, bin3 size: 2, bin3 max val: 10\n",
      "Result[3]: key: test/batch-ops2/id-2, bin1: 2, bin2: 21, bin3 size: 3, bin3 max val: 20\n",
      "Result[4]: key: test2/batch-ops/id-1, bin1: 1, bin2: 11, bin3 size: 2, bin3 max val: 10\n",
      "Result[5]: key: test2/batch-ops/id-2, bin1: 2, bin2: 21, bin3 size: 3, bin3 max val: 20\n",
      "Result[6]: key: test2/batch-ops2/id-1, bin1: 1, bin2: 11, bin3 size: 2, bin3 max val: 10\n",
      "Result[7]: key: test2/batch-ops2/id-2, bin1: 2, bin2: 21, bin3 size: 3, bin3 max val: 20\n"
     ]
    }
   ],
   "source": [
    "// start with a clean initialized test data\n",
    "initializeTestData();\n",
    "\n",
    "// Batch of 8 keys, 2 in each of these namespace/set combinations: \n",
    "//   (test, batch-ops), (test, batch-ops2), (test2, batch-ops), (test2, batch-ops2)\n",
    "int NUM_KEYS = 8;\n",
    "Key[] keys = new Key[NUM_KEYS];\n",
    "for (int i = 0; i < NUM_KEYS/4; i++) {\n",
    "    keys[i] = new Key(Namespace1, Set1, KeyPrefix + (i+1));\n",
    "    keys[NUM_KEYS/4+i] = new Key(Namespace1, Set2, KeyPrefix + (i+1));\n",
    "    keys[2*NUM_KEYS/4+i] = new Key(Namespace2, Set1, KeyPrefix + (i+1));\n",
    "    keys[3*NUM_KEYS/4+i] = new Key(Namespace2, Set2, KeyPrefix + (i+1));\n",
    "}\n",
    "\n",
    "// Perform the following operations on the keys.\n",
    "//    1) Read: get bin1\n",
    "//    2) Write: increment bin2 by 1 \n",
    "//    3) Read: get bin2\n",
    "//    4) Write: add a map element (0, 0) to bin3\n",
    "//    5) Read: get the largest value in the map bin3\n",
    "\n",
    "// send the multi-key operate batch request\n",
    "BatchResults bresults = client.operate(null, null, keys,\n",
    "    Operation.get(\"bin1\"),                                      // Op 1, single bin1 op\n",
    "    Operation.add(new Bin(\"bin2\", Value.get(1))),               // Op 2, first bin2 op\n",
    "    Operation.get(\"bin2\"),                                      // Op 3, second bin2 op\n",
    "    MapOperation.put(MapPolicy.Default, \"bin3\", Value.get(0), \n",
    "                        Value.get(0)),                          // Op 4, first bin3 op\n",
    "    MapOperation.getByRank(\"bin3\", -1, MapReturnType.VALUE)     // Op 5, second bin3 op\n",
    "    );\n",
    "\n",
    "// check if all operations succeeded\n",
    "if (bresults.status) {\n",
    "    System.out.println(\"All batch operations succeeded.\");\n",
    "}\n",
    "else {\n",
    "    System.out.println(\"Some batch operations failed.\");\n",
    "}\n",
    "\n",
    "// process the BatchResults returned from the batch operation\n",
    "for (int i = 0; i < bresults.records.length; i++) {\n",
    "    BatchRecord br = bresults.records[i];\n",
    "    Record rec = br.record;\n",
    "    if (br.resultCode == ResultCode.OK) {          // check individual key status \n",
    "        long bin1Val = rec.getLong(\"bin1\");        // bin1 has one operation, op result directly accessible\n",
    "        List<?> bin2Results = rec.getList(\"bin2\"); // bin2 and bin3 have multiple ops; access results through a list\n",
    "        List<?> bin3Results = rec.getList(\"bin3\");\n",
    "        // note the result order within each list matches ops order for the bin\n",
    "        System.out.format(\"Result[%d]: key: %s/%s/%s, bin1: %d, bin2: %d, bin3 size: %d, bin3 max val: %d\\n\", \n",
    "                            i, br.key.namespace, br.key.setName, br.key.userKey, bin1Val, (long)bin2Results.get(1), (long)bin3Results.get(0), (long)bin3Results.get(1));\n",
    "    }\n",
    "    else {   // error in individual key's operations\n",
    "        System.out.format(\"Result[%d]: key: %s, error: %s\\n\", \n",
    "                            i, br.key, ResultCode.getResultString(br.resultCode));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the database state. Note the changed `bin2` and `bin3` in keys `id-1` and `id-2` in the four sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records in database:\n",
      "Namespace: test, set: batch-ops: \n",
      "\tKey id-2: {bin1=2, bin2=21, bin3={0=0, 1=10, 2=20}}\n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-1: {bin1=1, bin2=11, bin3={0=0, 1=10}}\n",
      "Namespace: test, set: batch-ops2: \n",
      "\tKey id-2: {bin1=2, bin2=21, bin3={0=0, 1=10, 2=20}}\n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-1: {bin1=1, bin2=11, bin3={0=0, 1=10}}\n",
      "Namespace: test2, set: batch-ops: \n",
      "\tKey id-2: {bin1=2, bin2=21, bin3={0=0, 1=10, 2=20}}\n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-1: {bin1=1, bin2=11, bin3={0=0, 1=10}}\n",
      "Namespace: test2, set: batch-ops2: \n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-2: {bin1=2, bin2=21, bin3={0=0, 1=10, 2=20}}\n",
      "\tKey id-1: {bin1=1, bin2=11, bin3={0=0, 1=10}}\n"
     ]
    }
   ],
   "source": [
    "printRecords();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-key UDF Execute\n",
    "The multi-key batch UDF request allows the same UDF function to be executed across a batch of keys.  \n",
    "\n",
    "`\n",
    "BatchResults execute(BatchPolicy batchPolicy,\n",
    "                    BatchUDFPolicy udfPolicy,\n",
    "                    Key[] keys, \n",
    "                    String packageName, \n",
    "                    String functionName, \n",
    "                    Value… functionArgs)\n",
    "`\n",
    "\n",
    "In the example below, we execute a read-write UDF function `increment_and_get` in the UDF module `update_example`. The function increments the specified bin's value and returns the new value.\n",
    "\n",
    "Note:\n",
    "- UDF results are obtained with `getUDFResult()`, which returns an `Object` value, which in turn must be typecast to the correct type to obtain the actual value. In the example below, the UDF returns the `bin2` value in a map.\n",
    "- A non-existent key returns a `key not found` error.\n",
    "- The batch policy option `respondAllKeys` governs if the batch processing should continue even if some record operations fail. Try setting it to false, and see the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some batch operations failed.\n",
      "Result[0]: key: test:batch-ops:id-0:7b4c6a2b86aa917acb41efc8485fb20040b5ec35, error: UDF returned error\n",
      "Result[1]: key: test/batch-ops/id-1, bin2: 11\n",
      "Result[2]: key: test/batch-ops/id-2, bin2: 21\n",
      "Result[3]: key: test/batch-ops2/id-1, bin2: 11\n",
      "Result[4]: key: test/batch-ops2/id-2, bin2: 21\n",
      "Result[5]: key: test2/batch-ops/id-1, bin2: 11\n",
      "Result[6]: key: test2/batch-ops/id-2, bin2: 21\n",
      "Result[7]: key: test2/batch-ops2/id-1, bin2: 11\n",
      "Result[8]: key: test2/batch-ops2/id-2, bin2: 21\n"
     ]
    }
   ],
   "source": [
    "// start with a clean initialized test data\n",
    "initializeTestData();\n",
    "\n",
    "// create a batch of 8 keys, 2 in each of these namespace/set combinations: \n",
    "//   (test, batch-ops), (test, batch-ops2), (test2, batch-ops), (test2, batch-ops2)\n",
    "int NUM_KEYS = 9;  // one extra slot for a non-existent key\n",
    "Key[] keys = new Key[NUM_KEYS];\n",
    "// add a non-existent key 0 to test the error path\n",
    "keys[0] = new Key(Namespace1, Set1, KeyPrefix + 0);\n",
    "// populate valid keys\n",
    "for (int i = 0; i < NUM_KEYS/4; i++) {\n",
    "    keys[i+1] = new Key(Namespace1, Set1, KeyPrefix + (i+1));\n",
    "    keys[NUM_KEYS/4+i+1] = new Key(Namespace1, Set2, KeyPrefix + (i+1));\n",
    "    keys[2*NUM_KEYS/4+i+1] = new Key(Namespace2, Set1, KeyPrefix + (i+1));\n",
    "    keys[3*NUM_KEYS/4+i+1] = new Key(Namespace2, Set2, KeyPrefix + (i+1));\n",
    "}\n",
    "\n",
    "// perform the UDF function \"increment_and_get\" on the keys. \n",
    "// the function takes the bin name and increment value as parameters.\n",
    "String UDFModule = \"update_example\";\n",
    "String UDFFunction = \"increment_and_get\";\n",
    "\n",
    "// send the multi-key execute batch request\n",
    "BatchPolicy bPolicy = new BatchPolicy(client.batchPolicyDefault);\n",
    "bPolicy.respondAllKeys = true;              // set to true/false and observe effect\n",
    "BatchResults bresults = client.execute(bPolicy, null, keys,\n",
    "                        UDFModule, UDFFunction,\n",
    "                        Value.get(\"bin2\"), \n",
    "                        Value.get(1)); // increment bin2 by 1\n",
    "\n",
    "// check if all operations succeeded\n",
    "if (bresults.status) {\n",
    "    System.out.println(\"All batch operations succeeded.\");\n",
    "}\n",
    "else {\n",
    "    System.out.println(\"Some batch operations failed.\");\n",
    "}\n",
    "\n",
    "// process the BatchResults returned from the batch operation\n",
    "for (int i = 0; i < bresults.records.length; i++) {\n",
    "    BatchRecord br = bresults.records[i];\n",
    "    Record rec = br.record;\n",
    "    if (br.resultCode == ResultCode.OK) {          // check individual key status \n",
    "        HashMap<?,?> udfMap = (HashMap<?,?>)rec.getUDFResult();   // cast udf result to map returned by udf\n",
    "        long bin2Val = (long)udfMap.get(\"bin2\");                  // extract bin2 value from map                                        // cast to map\n",
    "        System.out.format(\"Result[%d]: key: %s/%s/%s, bin2: %d\\n\", \n",
    "                            i, br.key.namespace, br.key.setName, br.key.userKey, bin2Val);\n",
    "    }\n",
    "    else {   // error in individual key's operations\n",
    "        System.out.format(\"Result[%d]: key: %s, error: %s\\n\", \n",
    "                            i, br.key, ResultCode.getResultString(br.resultCode));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the database state. Note the changed `bin2` value in keys `id-1` and `id-2` in the four sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records in database:\n",
      "Namespace: test, set: batch-ops: \n",
      "\tKey id-2: {bin1=2, bin2=21, bin3={1=10, 2=20}}\n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-1: {bin1=1, bin2=11, bin3={1=10}}\n",
      "Namespace: test, set: batch-ops2: \n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-2: {bin1=2, bin2=21, bin3={1=10, 2=20}}\n",
      "\tKey id-1: {bin1=1, bin2=11, bin3={1=10}}\n",
      "Namespace: test2, set: batch-ops: \n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-1: {bin1=1, bin2=11, bin3={1=10}}\n",
      "\tKey id-2: {bin1=2, bin2=21, bin3={1=10, 2=20}}\n",
      "Namespace: test2, set: batch-ops2: \n",
      "\tKey id-2: {bin1=2, bin2=21, bin3={1=10, 2=20}}\n",
      "\tKey id-1: {bin1=1, bin2=11, bin3={1=10}}\n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n"
     ]
    }
   ],
   "source": [
    "printRecords()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-key Delete\n",
    "The multi-key batch delete allows a batch of records to be deleted. \n",
    "\n",
    "`\n",
    "BatchResults delete(BatchPolicy batchPolicy, \n",
    "                    BatchDeletePolicy deletePolicy, \n",
    "                    Key[] keys)\n",
    "`\n",
    "\n",
    "The example below shows deletion of multiple records across the two namespaces and their sets.\n",
    "\n",
    "Note:\n",
    "- The batch operate request described earlier also allows deletion of records, in addition to  read/write operations.\n",
    "- A non-existent key returns a `key not found` error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some batch operations failed.\n",
      "Result[0]: key: test:batch-ops:id-0:7b4c6a2b86aa917acb41efc8485fb20040b5ec35, error: Key not found\n",
      "Result[1]: key: test/batch-ops/id-1 deleted.\n",
      "Result[2]: key: test/batch-ops/id-2 deleted.\n",
      "Result[3]: key: test/batch-ops2/id-1 deleted.\n",
      "Result[4]: key: test/batch-ops2/id-2 deleted.\n",
      "Result[5]: key: test2/batch-ops/id-1 deleted.\n",
      "Result[6]: key: test2/batch-ops/id-2 deleted.\n",
      "Result[7]: key: test2/batch-ops2/id-1 deleted.\n",
      "Result[8]: key: test2/batch-ops2/id-2 deleted.\n"
     ]
    }
   ],
   "source": [
    "// start with a clean initialized test data\n",
    "initializeTestData();\n",
    "\n",
    "// create a batch of 8 keys, 2 in each of these namespace/set combinations: \n",
    "//   (test, batch-ops), (test, batch-ops2), (test2, batch-ops), (test2, batch-ops2)\n",
    "int NUM_KEYS = 9;  // one extra slot for a non-existent key\n",
    "Key[] keys = new Key[NUM_KEYS];\n",
    "// add a non-existent key 0 to test the error path\n",
    "keys[0] = new Key(Namespace1, Set1, KeyPrefix + 0);\n",
    "// add valid keys\n",
    "for (int i = 0; i < NUM_KEYS/4; i++) {\n",
    "    keys[i+1] = new Key(Namespace1, Set1, KeyPrefix + (i+1));\n",
    "    keys[NUM_KEYS/4+i+1] = new Key(Namespace1, Set2, KeyPrefix + (i+1));\n",
    "    keys[2*NUM_KEYS/4+i+1] = new Key(Namespace2, Set1, KeyPrefix + (i+1));\n",
    "    keys[3*NUM_KEYS/4+i+1] = new Key(Namespace2, Set2, KeyPrefix + (i+1));\n",
    "}\n",
    "\n",
    "// send the multi-key delete batch request\n",
    "BatchResults bresults = client.delete(null, null, keys);\n",
    "\n",
    "// check if all operations succeeded\n",
    "if (bresults.status) {\n",
    "    System.out.println(\"All batch operations succeeded.\");\n",
    "}\n",
    "else {\n",
    "    System.out.println(\"Some batch operations failed.\");\n",
    "}\n",
    "\n",
    "// process the BatchResults returned from the batch operation\n",
    "for (int i = 0; i < bresults.records.length; i++) {\n",
    "    BatchRecord br = bresults.records[i];\n",
    "    Record rec = br.record;\n",
    "    if (br.resultCode == ResultCode.OK) {          // check individual key status \n",
    "        System.out.format(\"Result[%d]: key: %s/%s/%s deleted.\\n\",\n",
    "                                    i, br.key.namespace, br.key.setName, br.key.userKey);\n",
    "    }\n",
    "    else {   // error in individual key's operations\n",
    "        System.out.format(\"Result[%d]: key: %s, error: %s\\n\", \n",
    "                            i, br.key, ResultCode.getResultString(br.resultCode));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the database state. Note the keys `id-1` and `id-2` in the four sets have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records in database:\n",
      "Namespace: test, set: batch-ops: \n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "Namespace: test, set: batch-ops2: \n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "Namespace: test2, set: batch-ops: \n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "Namespace: test2, set: batch-ops2: \n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n"
     ]
    }
   ],
   "source": [
    "printRecords()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Batch Operate\n",
    "In the general form of the batch operation:\n",
    "- A `BatchRecord` is specified using a key and the specific operation details.\n",
    "- In the operation list, Read, Read-Write, Delete, and UDF operations are specified using the corresponding subclasses, namely, `BatchRead`, `BatchWrite`, `BatchDelete`, and `BatchUDF`.\n",
    "\n",
    "`\n",
    "boolean operate(BatchPolicy policy, \n",
    "                List<BatchRecord> records)\n",
    "`\n",
    "\n",
    "In the code example below, we perform the following set of operations on different keys.\n",
    "1. Read only operations with `BatchRead`.\n",
    "2. Read-Write operations with `BatchWrite`.\n",
    "3. Delete with `BatchDelete`.\n",
    "4. Read-Delete with `BatchWrite`.\n",
    "5. UDF execution with `BatchUDF`.\n",
    "\n",
    "Note:\n",
    "- Results of multiple operations on a single bin are obtained as an ordered list.\n",
    "- The general batch operate allows different operations to be peformed on different records. The batch operate described earlier allows the same set of operations across multiple records, and it does not allow UDF operations.\n",
    "- The general batch operate can also be used in place of any other batch API, including the multi-key operate, multi-key UDF execute, and multi-key delete APIs described above.\n",
    "- Read-only operations must use `BatchRead`, and in order to use `BatchWrite` there must be at least one write operation. Deletes can be performed with `BatchWrite` as well as `BatchDelete`.\n",
    "- `BatchUDF` results are obtained with `getUDFResult()`, which returns an `Object` value, which in turn must be typecast to the correct type to obtain the actual value. In the example below, the UDF returns the `bin2` value in a map.\n",
    "- The error `key-not-found` does not stop batch execution even when `respondAllKeys` policy is set to false. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some batch operations failed.\n",
      "Result[0]: key test/batch-ops/id-1, bin1: 1, bin3[1]: 10\n",
      "Result[1]: key test/batch-ops/id-2, bin2 results: [null, 21], bin3 results: [3, {0=0, 1=10, 2=20}]\n",
      "Result[2]: key test/batch-ops/id-3, deleted.\n",
      "Result[3]: key test2/batch-ops/id-1 (deleted), bin2 results: [null, 11], bin3 results: [2, {0=0, 1=10}]\n",
      "Result[4]: key test2/batch-ops/id-2, bin2: 21\n",
      "Result[5]: error: Key not found\n"
     ]
    }
   ],
   "source": [
    "// start with a clean initialized test data\n",
    "initializeTestData();\n",
    "\n",
    "// batch records array - each batch record holds a key and operations array\n",
    "// a batch record can be BatchRead, BatchWrite, BatchDelete, and BatchUDF, each\n",
    "//.  with specific restrictions on allowed operations.\n",
    "List<BatchRecord> batchRecords = new ArrayList<BatchRecord>();\n",
    "\n",
    "// 1. Read only operations with BatchRead.\n",
    "Operation[] ops1 = Operation.array(\n",
    "                        Operation.get(\"bin1\"),\n",
    "                        MapOperation.getByKey(\"bin3\", Value.get(1), MapReturnType.VALUE));\n",
    "batchRecords.add(new BatchRead(new Key(Namespace1, Set1, KeyPrefix + 1), ops1));\n",
    "\n",
    "// 2. Read-Write operations with BatchWrite.\n",
    "Operation[] ops2 = Operation.array(\n",
    "                        Operation.add(new Bin(\"bin2\", Value.get(1))),\n",
    "                        Operation.get(\"bin2\"),\n",
    "                        MapOperation.put(MapPolicy.Default, \"bin3\", Value.get(0), Value.get(0)),\n",
    "                        Operation.get(\"bin3\"));\n",
    "batchRecords.add(new BatchWrite(new Key(Namespace1, Set1, KeyPrefix + 2), ops2));\n",
    "\n",
    "// 3. Delete with BatchDelete.\n",
    "batchRecords.add(new BatchDelete(new Key(Namespace1, Set1, KeyPrefix + 3)));\n",
    "\n",
    "// 4. Read-Write-Delete with BatchWrite.\n",
    "Operation[] ops4 = Operation.array(\n",
    "                        Operation.add(new Bin(\"bin2\", Value.get(1))),\n",
    "                        Operation.get(\"bin2\"),\n",
    "                        MapOperation.put(MapPolicy.Default, \"bin3\", Value.get(0), Value.get(0)),\n",
    "                        Operation.get(\"bin3\"),\n",
    "                        Operation.delete());\n",
    "batchRecords.add(new BatchWrite(new Key(Namespace2, Set1, KeyPrefix + 1), ops4));\n",
    "\n",
    "// 5. UDF execution with BatchUDF.\n",
    "batchRecords.add(new BatchUDF(new Key(Namespace2, Set1, KeyPrefix + 2), \n",
    "                                UDFModule,\n",
    "                                UDFFunction,\n",
    "                                new Value[]{Value.get(\"bin2\"), Value.get(1)}));\n",
    "\n",
    "// 6. Non-existent key operation.\n",
    "batchRecords.add(new BatchRead(new Key(Namespace1, Set1, KeyPrefix + 0), ops1));  // key 0 does not exist\n",
    "\n",
    "// execute the batch\n",
    "BatchPolicy bPolicy = new BatchPolicy(client.batchPolicyDefault);\n",
    "bPolicy.respondAllKeys = false;              // note key-not-found does not stop batch execution\n",
    "try {\n",
    "    boolean status = client.operate(bPolicy, batchRecords);\n",
    "    if (status) {\n",
    "        System.out.println(\"All batch operations succeeded.\");\n",
    "    }\n",
    "    else {\n",
    "        System.out.println(\"Some batch operations failed.\");      \n",
    "    }\n",
    "}\n",
    "catch (AerospikeException e) {\n",
    "   System.out.format(\"%s\", e);\n",
    "}\n",
    "\n",
    "// get and show results\n",
    "// 1. Read-Only operations with BatchRead.\n",
    "int i = 0;\n",
    "BatchRecord batchRec = batchRecords.get(i);\n",
    "Record rec = batchRec.record;\n",
    "Key key = batchRec.key;\n",
    "if (batchRec.resultCode == ResultCode.OK) {\n",
    "    Object v1 = rec.getValue(\"bin1\");\n",
    "    Object v2 = rec.getValue(\"bin3\");\n",
    "    System.out.format(\"Result[%d]: key %s/%s/%s, bin1: %s, bin3[1]: %s\\n\", \n",
    "                        i, key.namespace, key.setName, key.userKey, v1, v2);\n",
    "}\n",
    "else {\n",
    "    System.out.format(\"Result[%d]: error: %s\\n\", i, ResultCode.getResultString(batchRec.resultCode));\n",
    "}\n",
    "\n",
    "// 2. Read-Write operations with BatchWrite.\n",
    "i = 1;\n",
    "batchRec = batchRecords.get(i);\n",
    "rec = batchRec.record;\n",
    "key = batchRec.key;\n",
    "if (batchRec.resultCode == ResultCode.OK) {\n",
    "    Object v1 = rec.getValue(\"bin2\");\n",
    "    Object v2 = rec.getValue(\"bin3\");\n",
    "    System.out.format(\"Result[%d]: key %s/%s/%s, bin2 results: %s, bin3 results: %s\\n\", \n",
    "                        i, key.namespace, key.setName, key.userKey, v1, v2);\n",
    "}\n",
    "else {\n",
    "    System.out.format(\"Result[%d]: error: %s\\n\", i, ResultCode.getResultString(batchRec.resultCode));\n",
    "}\n",
    "\n",
    "// 3. Delete with BatchDelete.\n",
    "i = 2;\n",
    "batchRec = batchRecords.get(i);\n",
    "rec = batchRec.record;\n",
    "key = batchRec.key;\n",
    "if (batchRec.resultCode == ResultCode.OK) {\n",
    "    System.out.format(\"Result[%d]: key %s/%s/%s, deleted.\\n\", \n",
    "                        i, key.namespace, key.setName, key.userKey);\n",
    "}\n",
    "else {\n",
    "    System.out.format(\"Result[%d]: error: %s\\n\", i, ResultCode.getResultString(batchRec.resultCode));\n",
    "}\n",
    "\n",
    "// 4. Read-Write-Delete with BatchWrite.\n",
    "i = 3;\n",
    "batchRec = batchRecords.get(i);\n",
    "rec = batchRec.record;\n",
    "key = batchRec.key;\n",
    "if (batchRec.resultCode == ResultCode.OK) {\n",
    "    Object v1 = rec.getValue(\"bin2\");\n",
    "    Object v2 = rec.getValue(\"bin3\");\n",
    "    System.out.format(\"Result[%d]: key %s/%s/%s (deleted), bin2 results: %s, bin3 results: %s\\n\", \n",
    "                        i, key.namespace, key.setName, key.userKey, v1, v2);\n",
    "}\n",
    "else {\n",
    "    System.out.format(\"Result[%d]: error: %s\\n\", i, ResultCode.getResultString(batchRec.resultCode));\n",
    "}\n",
    "\n",
    "// 5. UDF execution with BatchUDF.\n",
    "i = 4;\n",
    "batchRec = batchRecords.get(i);\n",
    "rec = batchRec.record;\n",
    "key = batchRec.key;\n",
    "if (batchRec.resultCode == ResultCode.OK) {\n",
    "    HashMap<?,?> udfMap = (HashMap<?,?>)rec.getUDFResult();   // cast udf result to map returned by udf\n",
    "    long bin2Val = (long)udfMap.get(\"bin2\");                  // extract bin2 value from map                                        // cast to map\n",
    "    System.out.format(\"Result[%d]: key %s/%s/%s, bin2: %s\\n\", \n",
    "                        i, key.namespace, key.setName, key.userKey, bin2Val);\n",
    "}\n",
    "else {\n",
    "    System.out.format(\"Result[%d]: error: %s\\n\", i, ResultCode.getResultString(batchRec.resultCode));\n",
    "}\n",
    "\n",
    "// 6. Non-existent key operation.\n",
    "i = 5;\n",
    "batchRec = batchRecords.get(i);\n",
    "rec = batchRec.record;\n",
    "key = batchRec.key;\n",
    "if (batchRec.resultCode == ResultCode.OK) {\n",
    "    Object v1 = rec.getValue(\"bin1\");\n",
    "    Object v2 = rec.getValue(\"bin3\");\n",
    "    System.out.format(\"Result[%d]: key %s/%s/%s, bin1: %s, bin3[1]: %s\\n\", \n",
    "                        i, key.namespace, key.setName, key.userKey, v1, v2);\n",
    "}\n",
    "else {\n",
    "    System.out.format(\"Result[%d]: error: %s\\n\", i, ResultCode.getResultString(batchRec.resultCode));\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify database state. Note updates to test/batch-ops/id-2 and test2/batch-ops/id-2, and removal of test2/batch-ops/id-1 and test/batch-ops/id-3.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records in database:\n",
      "Namespace: test, set: batch-ops: \n",
      "\tKey id-1: {bin1=1, bin2=10, bin3={1=10}}\n",
      "\tKey id-2: {bin1=2, bin2=21, bin3={0=0, 1=10, 2=20}}\n",
      "Namespace: test, set: batch-ops2: \n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-1: {bin1=1, bin2=10, bin3={1=10}}\n",
      "\tKey id-2: {bin1=2, bin2=20, bin3={1=10, 2=20}}\n",
      "Namespace: test2, set: batch-ops: \n",
      "\tKey id-2: {bin1=2, bin2=21, bin3={1=10, 2=20}}\n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "Namespace: test2, set: batch-ops2: \n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-2: {bin1=2, bin2=20, bin3={1=10, 2=20}}\n",
      "\tKey id-1: {bin1=1, bin2=10, bin3={1=10}}\n"
     ]
    }
   ],
   "source": [
    "printRecords();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Related Topics\n",
    "We will discuss the following topics related to the new batch functionality:\n",
    "- Read and Write operation expressions\n",
    "- Filter expressions\n",
    "- Inline processing\n",
    "- Asynchronous batch processing\n",
    "- Batch reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Read and Write Operation Expressions\n",
    "Expressions were introduced in Aerospike Database 5.7 release. Filter Expressions are used in the request policy to select records for processing. Read or Write Operation Expressions are used to retrieve a server side computation result or update a bin with it. In batch requests, Operation Expressions can be used wherever Operation is allowed, that is, in all batch operate() APIs. \n",
    "\n",
    "Below is an example of multi-key operate using Operation Expressions. We use two operation expressions using multi-key batch operate API: a write expression to write to a new bin the results of a server side computation, and to read the results of another server side computation. The specific expression operations are:\n",
    "- Write expression: bin4 = (list of values from bin3 map) - (bin2 value)\n",
    "- Read expression: min(bin4) - bin1\n",
    "\n",
    "Note:\n",
    "- Below, the write expression does not write a null list to `bin4` for the key `id-1`, therefore the read expression fails.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some batch operations failed.\n",
      "Result[0]: key: test:batch-ops:id-1:ca0d67e46d385d7634d5c845f762f9e9cd66757e, error: Operation not applicable\n",
      "Result[1]: key: test/batch-ops/id-2, write-exp result: null, read-exp: 8\n",
      "Result[2]: key: test/batch-ops/id-3, write-exp result: null, read-exp: 7\n"
     ]
    }
   ],
   "source": [
    "// start with a clean initialized test data\n",
    "initializeTestData();\n",
    "\n",
    "// create a batch of 3 keys in (test, batch-ops)\n",
    "int NUM_KEYS = 3;  \n",
    "Key[] keys = new Key[NUM_KEYS];\n",
    "// add keys\n",
    "for (int i = 0; i < NUM_KEYS; i++) {\n",
    "    keys[i] = new Key(Namespace1, Set1, KeyPrefix + (i+1));\n",
    "}\n",
    "\n",
    "// create write and read expressions\n",
    "// new list = list of values from bin3 map - bin2 value\n",
    "Expression writeExp = Exp.build(\n",
    "                        ListExp.removeByValue(Exp.intBin(\"bin2\"),\n",
    "                            MapExp.getByIndexRange(MapReturnType.VALUE, \n",
    "                                Exp.val(0), Exp.val(100), Exp.mapBin(\"bin3\"))));                                \n",
    "// min(bin4) - bin1\n",
    "Expression readExp = Exp.build(\n",
    "                        Exp.sub(\n",
    "                            ListExp.getByRank(ListReturnType.VALUE, Exp.Type.INT,\n",
    "                                                 Exp.val(0), Exp.listBin(\"bin4\")),\n",
    "                            Exp.intBin(\"bin1\")));\n",
    "\n",
    "// send the multi-key operate batch request with write and read expressions\n",
    "BatchResults bresults = client.operate(null, null, keys, \n",
    "                            ExpOperation.write(\"bin4\", writeExp, ExpWriteFlags.DEFAULT),\n",
    "                            ExpOperation.read(\"read-exp\", readExp, ExpReadFlags.DEFAULT));\n",
    "\n",
    "// check if all operations succeeded\n",
    "if (bresults.status) {\n",
    "    System.out.println(\"All batch operations succeeded.\");\n",
    "}\n",
    "else {\n",
    "    System.out.println(\"Some batch operations failed.\");\n",
    "}\n",
    "\n",
    "// process the BatchResults returned from the batch operation\n",
    "for (int i = 0; i < bresults.records.length; i++) {\n",
    "    BatchRecord br = bresults.records[i];\n",
    "    Record rec = br.record;\n",
    "    if (br.resultCode == ResultCode.OK) {          // check individual key status \n",
    "        Object wResult = rec.getValue(\"bin4\");     // get op result for bin4\n",
    "        Object rResult = rec.getValue(\"read-exp\"); // get op result for read-exp\n",
    "\n",
    "        System.out.format(\"Result[%d]: key: %s/%s/%s, write-exp result: %s, read-exp: %s\\n\",\n",
    "                                    i, br.key.namespace, br.key.setName, br.key.userKey,\n",
    "                                    wResult, rResult);\n",
    "    }\n",
    "    else {   // error in individual key's operations\n",
    "        System.out.format(\"Result[%d]: key: %s, error: %s\\n\", \n",
    "                            i, br.key, ResultCode.getResultString(br.resultCode));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify database state. Note test/batch-ops records: `id-2` and `id-3` are changed, but `id-1` has no `bin4`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records in database:\n",
      "Namespace: test, set: batch-ops: \n",
      "\tKey id-2: {bin1=2, bin2=20, bin3={1=10, 2=20}, bin4=[10]}\n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}, bin4=[10, 20]}\n",
      "\tKey id-1: {bin1=1, bin2=10, bin3={1=10}}\n",
      "Namespace: test, set: batch-ops2: \n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-2: {bin1=2, bin2=20, bin3={1=10, 2=20}}\n",
      "\tKey id-1: {bin1=1, bin2=10, bin3={1=10}}\n",
      "Namespace: test2, set: batch-ops: \n",
      "\tKey id-1: {bin1=1, bin2=10, bin3={1=10}}\n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-2: {bin1=2, bin2=20, bin3={1=10, 2=20}}\n",
      "Namespace: test2, set: batch-ops2: \n",
      "\tKey id-1: {bin1=1, bin2=10, bin3={1=10}}\n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-2: {bin1=2, bin2=20, bin3={1=10, 2=20}}\n"
     ]
    }
   ],
   "source": [
    "printRecords();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Filter Expressions with Batch Processing\n",
    "Filter expressions are typically set in the `BatchPolicy`. When set in operation-specific policy such as `BatchWritePolicy` or `BatchDeletePolicy`, a filter expression is ignored in the multi-key operation request, but in general batch operate request it takes precedence over the one set in the `BatchPolicy`. This is in line with the goal of the two batch operations: multi-key operation is meant for the same operations and filter over multiple records, whereas general batch operate is meant for different operations and potentially different filters over individual records.\n",
    "\n",
    "In the multi-key delete example below, we set two different filters: \n",
    "1. in `BatchPolicy`: 5 <= bin2 <= 25 selecting keys `id-1` and `id-2`, and \n",
    "2. in `BatchDeletePolicy`: 15 <= bin2 <= 35 selecting keys `id-2` and `id-3`. \n",
    "\n",
    "Note, only `BatchPolicy` filter has effect as the operation deletes keys `id-1` and `id-2`. Also, `filtered out` error does not stop batch execution. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some batch operations failed.\n",
      "Result[0]: key: test:batch-ops:id-1:ca0d67e46d385d7634d5c845f762f9e9cd66757e, error: Transaction filtered out\n",
      "Result[1]: key: test/batch-ops/id-2 deleted.\n",
      "Result[2]: key: test/batch-ops/id-3 deleted.\n"
     ]
    }
   ],
   "source": [
    "// start with a clean initialized test data\n",
    "initializeTestData();\n",
    "\n",
    "// expression filter 5 <= bin2 <= 25 \n",
    "BatchPolicy bPolicy = new BatchPolicy(client.batchPolicyDefault);\n",
    "bPolicy.filterExp = Exp.build(                     // set the filter in batch policy\n",
    "    Exp.and(\n",
    "        Exp.ge(Exp.intBin(\"bin2\"), Exp.val(5)),\n",
    "        Exp.le(Exp.intBin(\"bin2\"), Exp.val(25))));\n",
    "\n",
    "// expression filter 15 <= bin2 <= 35 \n",
    "BatchDeletePolicy bdPolicy = new BatchDeletePolicy(client.batchDeletePolicyDefault);\n",
    "bdPolicy.filterExp = Exp.build(                    // is ignored\n",
    "    Exp.and(\n",
    "        Exp.ge(Exp.intBin(\"bin2\"), Exp.val(15)),\n",
    "        Exp.le(Exp.intBin(\"bin2\"), Exp.val(35))));\n",
    "\n",
    "// create a batch of 3 keys in (test, batch-ops)\n",
    "int NUM_KEYS = 3;  \n",
    "Key[] keys = new Key[NUM_KEYS];\n",
    "// add keys\n",
    "for (int i = 0; i < NUM_KEYS; i++) {\n",
    "    keys[i] = new Key(Namespace1, Set1, KeyPrefix + (i+1));\n",
    "}\n",
    "\n",
    "// send the multi-key delete batch request\n",
    "BatchResults bresults = client.delete(bPolicy, bdPolicy, keys);\n",
    "\n",
    "// check if all operations succeeded\n",
    "if (bresults.status) {\n",
    "    System.out.println(\"All batch operations succeeded.\");\n",
    "}\n",
    "else {\n",
    "    System.out.println(\"Some batch operations failed.\");\n",
    "}\n",
    "\n",
    "// process the BatchResults returned from the batch operation\n",
    "for (int i = 0; i < bresults.records.length; i++) {\n",
    "    BatchRecord br = bresults.records[i];\n",
    "    Record rec = br.record;\n",
    "    if (br.resultCode == ResultCode.OK) {          // check individual key status \n",
    "        System.out.format(\"Result[%d]: key: %s/%s/%s deleted.\\n\",\n",
    "                                    i, br.key.namespace, br.key.setName, br.key.userKey);\n",
    "    }\n",
    "    else {   // error in individual key's operations\n",
    "        System.out.format(\"Result[%d]: key: %s, error: %s\\n\", \n",
    "                            i, br.key, ResultCode.getResultString(br.resultCode));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Processing\n",
    "Both namespaces in this notebook container are in-memory namespaces, and therefore batch operations are processed inline by default. \n",
    "\n",
    "In a general batch operate, we will execute these operations on the same record bin:\n",
    "1. write+read\n",
    "2. read \n",
    "3. UDF write+read\n",
    "4. read\n",
    "\n",
    "If these operations execute in sequence or \"in line\", we expect the following:\n",
    "1. The reads in 1 and 2 should return the same value.\n",
    "2. The read in 3 and 4 should return the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result[0]: bin2: [null, 11]\n",
      "Result[1]: bin2: 10\n",
      "Result[2]: bin2: 12\n",
      "Result[3]: bin2: 12\n"
     ]
    }
   ],
   "source": [
    "// start with a clean initialized test data\n",
    "initializeTestData();\n",
    "\n",
    "// batch records array - each batch record holds a key and operations array\n",
    "List<BatchRecord> batchRecords = new ArrayList<BatchRecord>();\n",
    "\n",
    "// 1. write+read\n",
    "Operation[] ops1 = Operation.array(\n",
    "                        Operation.add(new Bin(\"bin2\", Value.get(1))),\n",
    "                        Operation.get(\"bin2\"));\n",
    "batchRecords.add(new BatchWrite(new Key(Namespace1, Set1, KeyPrefix + 1), ops1));\n",
    "\n",
    "// 2. read \n",
    "Operation[] ops2 = Operation.array(\n",
    "                        Operation.get(\"bin2\"));\n",
    "batchRecords.add(new BatchRead(new Key(Namespace1, Set1, KeyPrefix + 1), ops2));\n",
    "\n",
    "// 3. UDF write+read\n",
    "batchRecords.add(new BatchUDF(new Key(Namespace1, Set1, KeyPrefix + 1), \n",
    "                                UDFModule,\n",
    "                                UDFFunction,\n",
    "                                new Value[]{Value.get(\"bin2\"), Value.get(1)}));\n",
    "// 4. read\n",
    "Operation[] ops4 = Operation.array(\n",
    "                        Operation.get(\"bin2\"));\n",
    "batchRecords.add(new BatchRead(new Key(Namespace1, Set1, KeyPrefix + 1), ops4));\n",
    "\n",
    "\n",
    "// execute the batch\n",
    "BatchPolicy bPolicy = new BatchPolicy(client.batchPolicyDefault);\n",
    "bPolicy.allowInline = false;       // set true or false and examine results \n",
    "try {\n",
    "   client.operate(bPolicy, batchRecords);\n",
    "}\n",
    "catch (AerospikeException e) {\n",
    "   System.out.format(\"%s\", e);\n",
    "}\n",
    "\n",
    "// get and show results\n",
    "// 1. write+read\n",
    "int i = 0;\n",
    "BatchRecord batchRec = batchRecords.get(i);\n",
    "Record rec = batchRec.record;\n",
    "if (batchRec.resultCode == ResultCode.OK) {\n",
    "    Object v1 = rec.getValue(\"bin2\");\n",
    "    System.out.format(\"Result[%d]: bin2: %s\\n\", i,  v1);\n",
    "}\n",
    "else {\n",
    "    System.out.format(\"Result[%d]: error: %s\\n\", i, ResultCode.getResultString(batchRec.resultCode));\n",
    "}\n",
    "\n",
    "// 2. read\n",
    "i = 1;\n",
    "batchRec = batchRecords.get(i);\n",
    "rec = batchRec.record;\n",
    "if (batchRec.resultCode == ResultCode.OK) {\n",
    "    Object v1 = rec.getValue(\"bin2\");\n",
    "    System.out.format(\"Result[%d]: bin2: %s\\n\", i,  v1);\n",
    "}\n",
    "else {\n",
    "    System.out.format(\"Result[%d]: error: %s\\n\", i, ResultCode.getResultString(batchRec.resultCode));\n",
    "}\n",
    "\n",
    "\n",
    "// 3. UDF write+read\n",
    "i = 2;\n",
    "batchRec = batchRecords.get(i);\n",
    "rec = batchRec.record;\n",
    "if (batchRec.resultCode == ResultCode.OK) {\n",
    "    HashMap<?,?> udfMap = (HashMap<?,?>)rec.getUDFResult();   // cast udf result to map returned by udf\n",
    "    Object v1 = udfMap.get(\"bin2\");                  // extract bin2 value from map                                        // cast to map\n",
    "    System.out.format(\"Result[%d]: bin2: %s\\n\", i,  v1);\n",
    "}\n",
    "else {\n",
    "    System.out.format(\"Result[%d]: error: %s\\n\", i, ResultCode.getResultString(batchRec.resultCode));\n",
    "}\n",
    "\n",
    "// 4. read\n",
    "i = 3;\n",
    "batchRec = batchRecords.get(i);\n",
    "rec = batchRec.record;\n",
    "if (batchRec.resultCode == ResultCode.OK) {\n",
    "    Object v1 = rec.getValue(\"bin2\");\n",
    "    System.out.format(\"Result[%d]: bin2: %s\\n\", i,  v1);\n",
    "}\n",
    "else {\n",
    "    System.out.format(\"Result[%d]: error: %s\\n\", i, ResultCode.getResultString(batchRec.resultCode));\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Example\n",
    "In this example, we have a large batch size. A bin in the same record is incremented if it has the expected value if processing is strictly inline, otherwise the write operation will generate an error.\n",
    "\n",
    "Set the `allowInline` flag to true or false and observe the results. Note the value of `bin2` for the `test/batch-ops/id-2` key. It should be the number of iterations + 10 if all operations successfully executed inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of 100 records, with flags allowInline=false.\n",
      "Done.\n",
      "Records in database:\n",
      "Namespace: test, set: batch-ops: \n",
      "\tKey id-2: {bin1=2, bin2=20, bin3={1=10, 2=20}}\n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-1: {bin1=1, bin2=11, bin3={1=10}}\n",
      "Namespace: test, set: batch-ops2: \n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-2: {bin1=2, bin2=20, bin3={1=10, 2=20}}\n",
      "\tKey id-1: {bin1=1, bin2=10, bin3={1=10}}\n",
      "Namespace: test2, set: batch-ops: \n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-1: {bin1=1, bin2=10, bin3={1=10}}\n",
      "\tKey id-2: {bin1=2, bin2=20, bin3={1=10, 2=20}}\n",
      "Namespace: test2, set: batch-ops2: \n",
      "\tKey id-1: {bin1=1, bin2=10, bin3={1=10}}\n",
      "\tKey id-3: {bin1=3, bin2=30, bin3={1=10, 2=20, 3=30}}\n",
      "\tKey id-2: {bin1=2, bin2=20, bin3={1=10, 2=20}}\n"
     ]
    }
   ],
   "source": [
    "// start with a clean initialized test data\n",
    "initializeTestData();\n",
    "\n",
    "// batch records array - each batch record holds a key and operations array\n",
    "List<BatchRecord> batchRecords = new ArrayList<BatchRecord>();\n",
    "\n",
    "// create a batch of 100 - on same record in (test, batch-ops) \n",
    "int NUM_ITERS = 100;\n",
    "\n",
    "// create write and read expressions\n",
    "// increment bin2 by (1 if bin2 == expected value else unknown)\n",
    "int expectedBinVal = 10;\n",
    "for (int i = 0; i < NUM_ITERS; i++) {\n",
    "    Expression writeExp = Exp.build(\n",
    "                            Exp.add(Exp.intBin(\"bin2\"), \n",
    "                                Exp.cond(\n",
    "                                    Exp.eq(Exp.intBin(\"bin2\"), Exp.val(expectedBinVal)), Exp.val(1),\n",
    "                                    Exp.val(0))));\n",
    "                                    //Exp.unknown())));\n",
    "    Operation[] ops = Operation.array(\n",
    "                            ExpOperation.write(\"bin2\", writeExp, ExpWriteFlags.DEFAULT));\n",
    "    batchRecords.add(new BatchWrite(new Key(Namespace1, Set1, KeyPrefix + 1), ops));\n",
    "    expectedBinVal++;\n",
    "}\n",
    "\n",
    "// execute the batch\n",
    "BatchPolicy bPolicy = new BatchPolicy(client.batchPolicyDefault);\n",
    "bPolicy.respondAllKeys = false;\n",
    "bPolicy.allowInline = false;     // set true or false and examine results \n",
    "\n",
    "System.out.format(\"Batch of %d records, with flags allowInline=%b.\\n\", \n",
    "                    NUM_ITERS, bPolicy.allowInline);\n",
    "\n",
    "try {\n",
    "   client.operate(bPolicy, batchRecords);\n",
    "}\n",
    "catch (AerospikeException e) {\n",
    "   System.out.format(\"%s\\n\", e);\n",
    "}\n",
    "\n",
    "System.out.println(\"Done.\");\n",
    "printRecords();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous Batch Processing \n",
    "Setting up the event loops for asynchronous processing is somewhat involved. There is a separate tutorial that walks through the steps; please refer to the tutorial on asynchronous processing [here](async_ops.ipynb).\n",
    "\n",
    "The functionality of each synchronous APIs is replicated in two asynchronous variations:\n",
    "- With a list listener callback: As the name suggests, the callback gets the list of all results from the batch in one invocation.\n",
    "- With a record listener callback: As the name suggests, the callback is called with every individual record in the batch.\n",
    "\n",
    "Readers are encouraged to take a synchronous batch API above and implement its async variants, borrowing the code from the [async processing tutorial](async_ops.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Reads\n",
    "The previously supported batch read APIs have not changed to ensure that the existing code using the batch read APIs does not break. However there are the following behavior changes: \n",
    "- By default, all keys in the request will be processed even if there are failures. In the old batch reads, if a node sub-batch returns an error, the entire batch operation fails.\n",
    "- Failures are returned separately for each record.\n",
    "- Operate also takes read expressions, which were introduced in 5.7.\n",
    "- Set names are always sent. The policy option sendSetName is ignored, and is deprecated.\n",
    "\n",
    "The read-only batch operations are illustrated [here](sql-select.ipynb). \n",
    "\n",
    "The newly added batch \"write\" operate and general batch operate functions described earlier also provide the read capabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways and Conclusion\n",
    "Batch requests can be effective in improving throughput as they allow one or more operations to be submitted for multiple records. Now Aerospike supports all write operations, deletes, and UDF functions in a batch mode. In this notebook we discussed and described the new batch APIs with code examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up\n",
    "Remove tutorial data and close connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T20:49:19.972650Z",
     "start_time": "2020-12-29T20:49:19.967344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed tutorial data and closed server connection.\n"
     ]
    }
   ],
   "source": [
    "client.truncate(null, Namespace1, null, null);\n",
    "client.truncate(null, Namespace2, null, null);\n",
    "client.close();\n",
    "System.out.println(\"Removed tutorial data and closed server connection.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Exploration and Resources\n",
    "Here are some links for further exploration\n",
    "\n",
    "Resources\n",
    "- Related notebooks\n",
    "    - [SQL Operations - Select](sql_select.ipynb)\n",
    "    - [Async Operations](async_ops.ipynb)\n",
    "- Blog posts\n",
    "    - [Batch Operations in Aerospike](https://developer.aerospike.com/blog/batch-operations-in-aerospike)\n",
    "- [Aerospike Developer Hub](https://developer.aerospike.com)\n",
    "- Github repos\n",
    "    - [Java code examples](https://github.com/aerospike/aerospike-client-java/tree/master/examples/src/com/aerospike/examples)\n",
    "- Documentation\n",
    "    - [Java Client](https://www.aerospike.com/docs/client/java/index.html)\n",
    "    - [Java API Reference](https://www.aerospike.com/apidocs/java/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Visit [Aerospike notebooks repo](https://github.com/aerospike-examples/interactive-notebooks) to run additional Aerospike notebooks. To run a different notebook, download the notebook from the repo to your local machine, and then click on File->Open, and select Upload."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.8+10-LTS"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
