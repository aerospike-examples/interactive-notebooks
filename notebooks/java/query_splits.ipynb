{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Splitting-Large-Data-Sets-for-Parallel-Processing-of-Queries\" data-toc-modified-id=\"Splitting-Large-Data-Sets-for-Parallel-Processing-of-Queries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Splitting Large Data Sets for Parallel Processing of Queries</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Prerequisites\" data-toc-modified-id=\"Prerequisites-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Prerequisites</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ensure-database-is-running\" data-toc-modified-id=\"Ensure-database-is-running-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Ensure database is running</a></span></li><li><span><a href=\"#Download-and-install-additional-components.\" data-toc-modified-id=\"Download-and-install-additional-components.-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Download and install additional components.</a></span></li><li><span><a href=\"#Initialize-Client\" data-toc-modified-id=\"Initialize-Client-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Initialize Client</a></span><ul class=\"toc-item\"><li><span><a href=\"#Initialize-event-loops-for-async-processing-mode\" data-toc-modified-id=\"Initialize-event-loops-for-async-processing-mode-1.3.3.1\"><span class=\"toc-item-num\">1.3.3.1&nbsp;&nbsp;</span>Initialize event loops for async processing mode</a></span></li><li><span><a href=\"#Initialize-client-with-event-loops\" data-toc-modified-id=\"Initialize-client-with-event-loops-1.3.3.2\"><span class=\"toc-item-num\">1.3.3.2&nbsp;&nbsp;</span>Initialize client with event loops</a></span></li></ul></li><li><span><a href=\"#Includes-and-Constants\" data-toc-modified-id=\"Includes-and-Constants-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>Includes and Constants</a></span></li><li><span><a href=\"#Populate-Test-Data.\" data-toc-modified-id=\"Populate-Test-Data.-1.3.5\"><span class=\"toc-item-num\">1.3.5&nbsp;&nbsp;</span>Populate Test Data.</a></span></li></ul></li></ul></li><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#Parallel-IO-Streams-within-Partition-with-Digest-Modulo\" data-toc-modified-id=\"Parallel-IO-Streams-within-Partition-with-Digest-Modulo-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Parallel IO Streams within Partition with Digest-Modulo</a></span></li><li><span><a href=\"#Dividing-Partitions-into-Splits\" data-toc-modified-id=\"Dividing-Partitions-into-Splits-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Dividing Partitions into Splits</a></span><ul class=\"toc-item\"><li><span><a href=\"#Examples-of-Split-Type-Assignments\" data-toc-modified-id=\"Examples-of-Split-Type-Assignments-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Examples of Split Type Assignments</a></span></li></ul></li><li><span><a href=\"#Parallel-Query-Framework\" data-toc-modified-id=\"Parallel-Query-Framework-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Parallel Query Framework</a></span><ul class=\"toc-item\"><li><span><a href=\"#Stream-Processing:-Aggregate-Computation\" data-toc-modified-id=\"Stream-Processing:-Aggregate-Computation-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Stream Processing: Aggregate Computation</a></span></li><li><span><a href=\"#Work-Scheduling:-Next-Available-Split\" data-toc-modified-id=\"Work-Scheduling:-Next-Available-Split-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Work Scheduling: Next Available Split</a></span></li><li><span><a href=\"#Global-parameters\" data-toc-modified-id=\"Global-parameters-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Global parameters</a></span></li></ul></li><li><span><a href=\"#Baseline-Runs\" data-toc-modified-id=\"Baseline-Runs-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Baseline Runs</a></span></li><li><span><a href=\"#Running-Parallel-Queries-with-Interesting-Parameter-Variations\" data-toc-modified-id=\"Running-Parallel-Queries-with-Interesting-Parameter-Variations-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Running Parallel Queries with Interesting Parameter Variations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Varying-number-of-splits-and-split-types\" data-toc-modified-id=\"Varying-number-of-splits-and-split-types-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Varying number of splits and split types</a></span></li><li><span><a href=\"#Varying-number-of-workers-in-sync-mode\" data-toc-modified-id=\"Varying-number-of-workers-in-sync-mode-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Varying number of workers in sync mode</a></span></li><li><span><a href=\"#Varying-number-of-workers-in-sync-and-async-mode\" data-toc-modified-id=\"Varying-number-of-workers-in-sync-and-async-mode-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Varying number of workers in sync and async mode</a></span></li><li><span><a href=\"#Varying-query-type-and-filter\" data-toc-modified-id=\"Varying-query-type-and-filter-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Varying query type and filter</a></span></li><li><span><a href=\"#Varying-max-records-chunk-size\" data-toc-modified-id=\"Varying-max-records-chunk-size-7.5\"><span class=\"toc-item-num\">7.5&nbsp;&nbsp;</span>Varying max-records chunk size</a></span></li><li><span><a href=\"#Partition-Slices:-A-New-Split-Assignment-Scheme\" data-toc-modified-id=\"Partition-Slices:-A-New-Split-Assignment-Scheme-7.6\"><span class=\"toc-item-num\">7.6&nbsp;&nbsp;</span>Partition Slices: A New Split Assignment Scheme</a></span></li><li><span><a href=\"#Select-and-run-with-your-own-parameters\" data-toc-modified-id=\"Select-and-run-with-your-own-parameters-7.7\"><span class=\"toc-item-num\">7.7&nbsp;&nbsp;</span>Select and run with your own parameters</a></span></li></ul></li><li><span><a href=\"#Takeaways-and-Conclusion\" data-toc-modified-id=\"Takeaways-and-Conclusion-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Takeaways and Conclusion</a></span></li><li><span><a href=\"#Further-Exploration-and-Resources\" data-toc-modified-id=\"Further-Exploration-and-Resources-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Further Exploration and Resources</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Large Data Sets for Parallel Processing of Queries\n",
    "This tutorial describes multiple schemes for dividing a large data set into equal splits for parallel processing of queries, and a test framework with multiple parameters.\n",
    "\n",
    "This notebook requires the Aerospike Database running locally with Java kernel and Aerospike Java Client. To create a Docker container that satisfies the requirements and holds a copy of Aerospike notebooks, visit the [Aerospike Notebooks Repo](https://github.com/aerospike-examples/interactive-notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook walks through:\n",
    "- implementing multiple schemes to divide a data set in Aerospike into equal splits that can be queried in parallel.\n",
    "- creating a test framework that allows the splits to be processed over a range of parameters such as the number of workers, query and filter options, processing mode, and more. \n",
    "- running various combinations of these parameters with the test data, and ensure the computation results remain the same for specific query and filter choices.\n",
    "\n",
    "Please refer to the adjunct blog post [Processing Large Data Sets with Fine Grained Streams](https://developer.aerospike.com/blog/fine-grained-streams) for additional discussion.\n",
    "\n",
    "The specific topics covered in this notebook include:\n",
    "- Understanding how the digest-module scheme for dividing a partition into multiple sub-partitions averts disk io bottleneck.\n",
    "- Schemes for dividing data equally over an arbitrary number of splits.\n",
    "- A test framework to process the splits in parallel using a range of parameters such as the number of workers, query and filter options, processing function, and sync and async modes.\n",
    "- Putting it to test with different values for splits, workers, query, filter, and processing mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "This tutorial assumes familiarity with the following topics:\n",
    "- [Hello World](hello_world.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure database is running\n",
    "This notebook requires that Aerospike database is running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io.github.spencerpark.ijava.IJava;\n",
    "import io.github.spencerpark.jupyter.kernel.magic.common.Shell;\n",
    "IJava.getKernelInstance().getMagics().registerMagics(Shell.class);\n",
    "%sh asd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and install additional components.\n",
    "Install the Java client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<dependencies>\n",
    "  <dependency>\n",
    "    <groupId>com.aerospike</groupId>\n",
    "    <artifactId>aerospike-client</artifactId>\n",
    "    <version>6.1.0</version>\n",
    "  </dependency>\n",
    "</dependencies>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Client\n",
    "Initialize the client that can be used for both sync and async processing modes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize event loops for async processing mode\n",
    "We will use async processing using NIO event loops, but the other event loop types may also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Throttles initialized for 2 loops with 50 concurrent operations per loop.\n"
     ]
    }
   ],
   "source": [
    "import java.util.concurrent.atomic.AtomicInteger;\n",
    "import com.aerospike.client.async.EventPolicy;\n",
    "import com.aerospike.client.async.EventLoops;\n",
    "import com.aerospike.client.async.EventLoop;\n",
    "import com.aerospike.client.async.Throttles;\n",
    "import com.aerospike.client.async.Monitor;\n",
    "import com.aerospike.client.async.NioEventLoops;\n",
    "import com.aerospike.client.listener.RecordSequenceListener;\n",
    "\n",
    "// initialize event loops \n",
    "final int NumLoops = 2;\n",
    "final int CommandsPerEventLoop = 50;\n",
    "final int DelayQueueSize = 50;\n",
    "\n",
    "EventPolicy eventPolicy = new EventPolicy();\n",
    "eventPolicy.maxCommandsInProcess = CommandsPerEventLoop;\n",
    "eventPolicy.maxCommandsInQueue = DelayQueueSize;\n",
    "EventLoops eventLoops = new NioEventLoops(eventPolicy, NumLoops);\n",
    "\n",
    "// initialize event loop throttles\n",
    "Throttles throttles = new Throttles(NumLoops, CommandsPerEventLoop);\n",
    "\n",
    "System.out.format(\"Throttles initialized for %s loops with %s concurrent operations per loop.\\n\", \n",
    "                    NumLoops, CommandsPerEventLoop);;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize client with event loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized the client and connected to the cluster.\n"
     ]
    }
   ],
   "source": [
    "import com.aerospike.client.AerospikeClient;\n",
    "import com.aerospike.client.Host;\n",
    "import com.aerospike.client.policy.ClientPolicy;\n",
    "\n",
    "// initialize the client \n",
    "final int MaxConnPerNode = 10000; // adjust accordingly for max workers\n",
    "ClientPolicy clientPolicy = new ClientPolicy();\n",
    "clientPolicy.maxConnsPerNode = MaxConnPerNode;\n",
    "clientPolicy.eventLoops = eventLoops;\n",
    "int concurrentMax = CommandsPerEventLoop * NumLoops;\n",
    "if (clientPolicy.maxConnsPerNode < concurrentMax) {\n",
    "    clientPolicy.maxConnsPerNode = concurrentMax; \n",
    "}\n",
    "Host[] hosts = Host.parseHosts(\"localhost\", 3000); \n",
    "AerospikeClient client = new AerospikeClient(clientPolicy, hosts);\n",
    "\n",
    "System.out.println(\"Initialized the client and connected to the cluster.\");;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Includes and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.util.concurrent.atomic.AtomicInteger;\n",
    "import java.util.concurrent.atomic.AtomicLong;\n",
    "import com.aerospike.client.AerospikeException;\n",
    "import com.aerospike.client.Bin;\n",
    "import com.aerospike.client.Key;\n",
    "import com.aerospike.client.policy.WritePolicy;\n",
    "import com.aerospike.client.query.Filter;\n",
    "import com.aerospike.client.query.PartitionFilter;\n",
    "import com.aerospike.client.query.RecordSet;\n",
    "import com.aerospike.client.query.Statement;\n",
    "import com.aerospike.client.Record;\n",
    "import com.aerospike.client.exp.Exp;\n",
    "import com.aerospike.client.policy.Policy;\n",
    "import com.aerospike.client.policy.QueryPolicy;\n",
    "import com.aerospike.client.query.IndexType;\n",
    "import com.aerospike.client.task.IndexTask;\n",
    "import com.aerospike.client.ResultCode;\n",
    "import com.aerospike.client.BatchRecord;\n",
    "import com.aerospike.client.BatchResults;\n",
    "import com.aerospike.client.BatchWrite;\n",
    "import com.aerospike.client.policy.BatchPolicy;\n",
    "import com.aerospike.client.policy.BatchWritePolicy;\n",
    "import com.aerospike.client.Operation;\n",
    "import com.aerospike.client.Value;\n",
    "\n",
    "final String Namespace = \"test\";\n",
    "final String Set = \"query-splits\";\n",
    "final String KeyPrefix = \"id-\";\n",
    "final Integer NumRecords = 100000;         // CHANGE TO THE REQUIRED NUMBER OF TEST DATA RECORDS\n",
    "\n",
    "final int MIN_NUM_SPLITS = 0;              // at-least the requested number of splits\n",
    "final int EXACT_NUM_SPLITS = 1;            // exactly the requested number of splits\n",
    "final int MAX_NUM_SPLITS = 2;              // at-most the requested number of splits\n",
    "final int EXACT_NUM_SPLITS_SLICED = 3;     // exactly the requested number of splits, a slice in each partition\n",
    "final int PROCESSING_MODE_SYNC = 0;        // sync processing mode\n",
    "final int PROCESSING_MODE_ASYNC = 1;       // async processing mode\n",
    "final int PRIMARY_INDEX_QUERY = 0;         // primary index query (scan)\n",
    "final int SECONDARY_INDEX_QUERY = 1;       // secondary index query - uses secondaryIndexQueryPredicate\n",
    "final int QUERY_FILTER_NONE = 0;           // no additional filter in query\n",
    "final int QUERY_FILTER_INCLUDE = 1;        // include the specified filter - uses includeQueryFilterExp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate Test Data.\n",
    "The test data consists of NumRecords records, each with a user key \"id-\\<i\\>\", an integer bin \"bin1\" with value i, and another integer bin with value 10*i, where 1 \\<= i \\<= NumRecords. An integer secondary index is created on \"bin1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data populated.\n"
     ]
    }
   ],
   "source": [
    "// convenience function to truncate test data\n",
    "void truncateTestData() {\n",
    "    try {\n",
    "        client.truncate(null, Namespace, Set, null);\n",
    "    }\n",
    "    catch (AerospikeException e) {\n",
    "        // ignore\n",
    "    }\n",
    "}\n",
    "\n",
    "// convenience function to initialize test data\n",
    "void initializeTestData() {\n",
    "    truncateTestData();\n",
    "    // Insert in batches for speed\n",
    "    BatchPolicy bPolicy = new BatchPolicy(client.batchPolicyDefault);\n",
    "    BatchWritePolicy wpolicy = new BatchWritePolicy();\n",
    "    wpolicy.sendKey = true;\n",
    "    int batchMaxSize = 100;\n",
    "    int recordIdx = 0;\n",
    "    while (recordIdx < NumRecords) {  \n",
    "        int batchSize = Math.min(batchMaxSize, NumRecords-recordIdx);\n",
    "        List<BatchRecord> batchRecords = new ArrayList<BatchRecord>();\n",
    "        for (int i=0; i < batchSize; i++) {\n",
    "            Operation[] ops = Operation.array(\n",
    "                                    Operation.put(new Bin(\"bin1\", Value.get(recordIdx+1))),\n",
    "                                    Operation.put(new Bin(\"bin2\", Value.get(10*(recordIdx+1)))),\n",
    "                                    Operation.put(new Bin(\"bin3\", Value.get(new byte[1000]))));\n",
    "            batchRecords.add(new BatchWrite(wpolicy, new Key(Namespace, Set, KeyPrefix + (recordIdx+1)), ops));\n",
    "            recordIdx++;\n",
    "        }   \n",
    "        // execute the batch\n",
    "        try {\n",
    "            boolean status = client.operate(bPolicy, batchRecords);\n",
    "            if (!status) {\n",
    "                System.out.println(\"Some batch operations failed.\");      \n",
    "            }\n",
    "        }\n",
    "        catch (AerospikeException e) {\n",
    "           System.out.format(\"%s\", e);\n",
    "        }\n",
    "    }       \n",
    "}\n",
    "initializeTestData();\n",
    "System.out.println(\"Test data populated.\");;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created index idx_bin1_number_idx on ns=test set=query-splits bin=bin1."
     ]
    }
   ],
   "source": [
    "Policy policy = new Policy();\n",
    "policy.socketTimeout = 0; // Do not timeout on index create.\n",
    "\n",
    "final String IndexName = \"idx_bin1_number_idx\";\n",
    "\n",
    "try {\n",
    "    IndexTask task = client.createIndex(policy, Namespace, Set, IndexName, \n",
    "                                        \"bin1\", IndexType.NUMERIC);\n",
    "    task.waitTillComplete();\n",
    "}\n",
    "catch (AerospikeException ae) {\n",
    "    if (ae.getResultCode() != ResultCode.INDEX_ALREADY_EXISTS) {\n",
    "        throw ae;\n",
    "    }\n",
    "}\n",
    "\n",
    "System.out.format(\"Created index %s on ns=%s set=%s bin=%s.\", \n",
    "                                    IndexName, Namespace, Set, \"bin1\");;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The main sections consist of:\n",
    "- Parallel IO Streams within Partition with Digest-Modulo\n",
    "- Dividing Partitions into Splits\n",
    "- Parallel Query Framework\n",
    "- Experimenting with Parameter Variations\n",
    "\n",
    "Note:\n",
    "- The notebook has server restarts. A restart can take some time before the server is ready to accept requests. If you see client errors after a restart, wait a bit longer. \n",
    "- The kernel could die if a specific run exceeds the resources available. In this case, reduce the number of workers below the breaking point in all cells, or if possible, increase the container resource limits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel IO Streams within Partition with Digest-Modulo\n",
    "In this section, we will establish why parallel io streams makes sense by dividing a partition into subpartitions. A parittion is divided into M subpartitions using `digest-modulo % M = s, for s=0 to M-1`. Each subpartition stream evaluates the digest-modulo expression for every record in the partition, but reads from device only the records in the subpartition. We will show the digest-modulo evaluation is much faster than reading a record from the device.\n",
    "\n",
    "To illustrate the difference, we will change the default config to eliminate buffering of data and force record data to be read from device. This allows us see the difference in speeds when a filter is computed purely in memory versus when it requires data on disk. We will evaluate the following filters:\n",
    "- Metadata or digest-modulo filter: digest % 100 = -1. This condition also is not true for any record, and no record is returned. However it can be evaluated from memory (a record digest is held in memory in the primary index) without reading the record.\n",
    "- Data filter: bin1 = -1. This condition is not true for any record, so no record is returned. But to evaluate it, a record must be read from the disk.\n",
    "\n",
    "The average query execution time for the two filters is printed. Note the difference and the fact that a metadata filter is much faster. For larger amount of data and/or slower device, the speed difference will be more pronounced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server restarted with unbuffered io.\n"
     ]
    }
   ],
   "source": [
    "// to run the test meaningfully, configure the namespace for unbuffered io and restart server\n",
    "// set data-in-memory in the default config to false, add direct-files=true for unbuffered io\n",
    "%sh cp /etc/aerospike/aerospike.conf /home/jovyan/notebooks/java/aerospike.conf\n",
    "%sh sed -i -e \"s/data-in-memory true.*/data-in-memory false/\" -e \"/data-in-memory.*/a direct-files true\" /home/jovyan/notebooks/java/aerospike.conf\n",
    "// start server with the modified config, sleep 10s for server to be ready to process requests\n",
    "%sh pkill asd\n",
    "%sh asd --config-file /home/jovyan/notebooks/java/aerospike.conf\n",
    "%sh sleep 10\n",
    "System.out.println(\"Server restarted with unbuffered io.\");;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time for a metadata filter: 333 milliseconds.\n",
      "Average time for a data filter: 3393 milliseconds.\n"
     ]
    }
   ],
   "source": [
    "// function that runs many iterations of a query and returns average execution time\n",
    "long getAvgQueryExecutionTimeMillis(QueryPolicy qPolicy, Statement stmt) {\n",
    "    int numIters = 2;\n",
    "    long startTime = System.currentTimeMillis();\n",
    "    for (int i=0; i < numIters; i++) {\n",
    "        RecordSet rs = client.query(qPolicy, stmt);\n",
    "        try {\n",
    "            while(rs.next()) {\n",
    "                Record rec = rs.getRecord();\n",
    "                // do something with the record - ignore here\n",
    "            }\n",
    "        }\n",
    "        finally {\n",
    "            rs.close();\n",
    "        }\n",
    "    }\n",
    "    long endTime = System.currentTimeMillis();\n",
    "    return (endTime - startTime)/numIters;\n",
    "}\n",
    "\n",
    "Statement stmt = new Statement();\n",
    "stmt.setNamespace(Namespace);\n",
    "stmt.setSetName(Set);\n",
    "stmt.setBinNames(\"bin1\", \"bin2\");\n",
    "stmt.setFilter(null);            // this query filter is null for a primary-index query\n",
    "QueryPolicy qPolicy = new QueryPolicy(client.queryPolicyDefault);\n",
    "qPolicy.socketTimeout = 120000; // 2 min\n",
    "qPolicy.maxRetries = 0; // do not retry\n",
    "\n",
    "\n",
    "// first, time the metadata filter\n",
    "// metadata filter is a digest-modulo expression which is always false\n",
    "Exp metadataFilterExp =  Exp.eq(Exp.digestModulo(100), Exp.val(-1));\n",
    "qPolicy.filterExp = Exp.build(metadataFilterExp); //  filter expression is specified in policy\n",
    "System.out.println(\"Average time for a metadata filter: \" + getAvgQueryExecutionTimeMillis(qPolicy, stmt) + \" milliseconds.\");\n",
    "\n",
    "// next, time the data filter\n",
    "// data filter is a equality expression which is always false\n",
    "Exp dataFilterExp =  Exp.eq(Exp.intBin(\"bin1\"), Exp.val(-1));\n",
    "qPolicy.filterExp = Exp.build(dataFilterExp); //  filter expression is specified in policy\n",
    "System.out.println(\"Average time for a data filter: \" + getAvgQueryExecutionTimeMillis(qPolicy, stmt) + \" milliseconds.\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server restarted with the default config.\n"
     ]
    }
   ],
   "source": [
    "// choose to revert to the default config with data-in-memory=true \n",
    "// so that the scenarios in this notebook will run quickly. \n",
    "%sh pkill asd\n",
    "%sh asd\n",
    "// sleep 10s for server to be ready to process requests\n",
    "%sh sleep 10\n",
    "System.out.println(\"Server restarted with the default config.\");;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing Partitions into Splits\n",
    "The main function assignSplits() returns an array of assignments across the requested number of splits. Each assignment has:\n",
    "\n",
    "Partial or full partition assignment\n",
    "A full partition assignment has the range of partitions, specified as the start partition id and count\n",
    "A partial partition assignment has a range of subpartitions, specified as the start subpartition id, count, and  modulo (division) factor. The subpartition range may be defined over one or more partitions.\n",
    "\n",
    "The assignment parameters directly correspond to the `PartitionFilter` specification in the `queryPartitions` API. For example, in Java, the query over full parttiions can be translated as follows:\n",
    "\n",
    "`\n",
    "Statement stmt = new Statement(); \n",
    "stmt.setNamespace(namespace); \n",
    "stmt.setSetName(setName); \n",
    "stmt.setBinNames(bin1, ...); \n",
    "stmt.setMaxRecords(maxRecords); \n",
    "PartitionFilter pFilter = PartitionFilter.range(startPartitionId, partitionCount) \n",
    "RecordSet rs = client.queryPartitions(qPolicy, qStatement, pFilter);\n",
    "`\n",
    "\n",
    "A query over sub-partition assignments is translated as follows:\n",
    "\n",
    "`\n",
    "PartitionFilter pFilter = PartitionFilter.range(startPartitionId, partitionCount) \n",
    "QueryPolicy qPolicy = new QueryPolicy(client.queryPolicyDefault); \n",
    "qPolicy.filterExp = Exp.build( \n",
    "                        Exp.and( \n",
    "                            Exp.ge(Exp.moduloDigest(moduloFactor), startSubpartitionId)), \n",
    "                            Exp.le(Exp.moduloDigest(moduloFactor), startSubpartitionId+subpartitionCount-1)));\n",
    "RecordSet rs = client.queryPartitions(qPolicy, qStatement, pFilter);\n",
    "`\n",
    "\n",
    "Each chunk of `maxRecords` records is processed, and the query is re-issued until `pFilter.isDone()` returns true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryPartition {\n",
    "    boolean isFullPartitionAssignment; // false for sub-partition assignments\n",
    "    Integer startPartitionId;\n",
    "    Integer partitionCount;\n",
    "    Integer subpartitionModuloFactor;\n",
    "    Integer startSubpartitionId;\n",
    "    Integer subpartitionCount;\n",
    "    \n",
    "    QueryPartition (int startPartitionId, int count) {\n",
    "        this.isFullPartitionAssignment = true;\n",
    "        this.startPartitionId = startPartitionId;\n",
    "        this.partitionCount = count;\n",
    "    }\n",
    "    \n",
    "    QueryPartition(int startPartitionId, int partitionCount, \n",
    "                    int moduloFactor, int startSubpartitionId, \n",
    "                    int subpartitionCount) {\n",
    "        this.isFullPartitionAssignment = false;\n",
    "        this.startPartitionId = startPartitionId;\n",
    "        this.partitionCount = partitionCount;\n",
    "        this.subpartitionModuloFactor = moduloFactor;\n",
    "        this.startSubpartitionId = startSubpartitionId;\n",
    "        this.subpartitionCount = subpartitionCount;                                   \n",
    "    }\n",
    "}\n",
    "\n",
    "class SplitAssignment {\n",
    "    List<QueryPartition> queryPartitions = new ArrayList<QueryPartition>();\n",
    "    \n",
    "    SplitAssignment(QueryPartition qp) {\n",
    "        this.queryPartitions.add(qp);\n",
    "    }\n",
    "    \n",
    "    void add(QueryPartition qp) {\n",
    "        this.queryPartitions.add(qp);\n",
    "    }\n",
    "}\n",
    "\n",
    "final int FactorsOf4096[] = {1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096};\n",
    "\n",
    "SplitAssignment[] assignMaxSplits(int reqSplits) {\n",
    "    int numSplits = 0;\n",
    "    SplitAssignment[] assignments = null;\n",
    "    if (reqSplits < 2*4096) {\n",
    "        // Case 1: N < 2*4096: Full partition assignments\n",
    "        // Closest approximation of splits, numSplits: factor of 4096 that is <= reqSplits\n",
    "        for (int i = FactorsOf4096.length - 1; i >= 0; i--) {\n",
    "            if (FactorsOf4096[i] <= reqSplits) {\n",
    "                numSplits = FactorsOf4096[i];\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "        // Number of partitions in each split, count: 4096/numSplits\n",
    "        int count = 4096 / numSplits;\n",
    "        // Partitions in split i: i*count to (i+1)*n (upper bound exclusive)\n",
    "        assignments = new SplitAssignment[numSplits];\n",
    "        for (int i = 0; i < numSplits; i++) {\n",
    "            QueryPartition qp = new QueryPartition(i*count, count);\n",
    "            assignments[i] = new SplitAssignment(qp);\n",
    "        }\n",
    "    } else {        \n",
    "        // Case 2: N >= 2*4096: Sub-partition assignment\n",
    "        //Closest approximation of splits, numSplits: multiple of 4096 that is <= reqSplits\n",
    "        numSplits = 4096 * (int)Math.floor((double)reqSplits/4096);\n",
    "        //Number of sub-partitions per partition, s: numSplits/4096\n",
    "        int moduloFactor = numSplits/4096;\n",
    "        //Sub-partition in split i: (floor(i/s), i%s, s)\n",
    "        assignments = new SplitAssignment[numSplits];\n",
    "        for (int i = 0; i < numSplits; i++) {\n",
    "            QueryPartition qp = new QueryPartition((int)Math.floor((double)i/moduloFactor), 1, \n",
    "                                                    moduloFactor, i % moduloFactor, 1);\n",
    "            assignments[i] = new SplitAssignment(qp);\n",
    "        }\n",
    "    }\n",
    "    return assignments;\n",
    "}\n",
    "\n",
    "SplitAssignment[] assignMinSplits(int reqSplits) {\n",
    "    int numSplits = 0;\n",
    "    SplitAssignment[] assignments = null;\n",
    "    if (reqSplits <= 4096) {\n",
    "        // Case 1: N <= 4096: Full partition assignments\n",
    "        // Closest approximation of splits, numSplits: factor of 4096 that is >= reqSplits\n",
    "        for (int f: FactorsOf4096) {\n",
    "            if (f >= reqSplits) {\n",
    "                numSplits = f;\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "        // Number of partitions in each split, count: 4096/numSplits\n",
    "        int count = 4096 / numSplits;\n",
    "        // Partitions in split i: i*count to (i+1)*n (upper bound exclusive)\n",
    "        assignments = new SplitAssignment[numSplits];\n",
    "        for (int i = 0; i < numSplits; i++) {\n",
    "            QueryPartition qp = new QueryPartition(i*count, count);\n",
    "            assignments[i] = new SplitAssignment(qp);\n",
    "        }\n",
    "    } else {        \n",
    "        // Case 2: N > 4096: Sub-partition assignment\n",
    "        //Closest approximation of splits, numSplits: multiple of 4096 that is >= reqSplits\n",
    "        numSplits = 4096 * (int)Math.ceil((double)reqSplits/4096);\n",
    "        //Number of sub-partitions per partition, s: numSplits/4096\n",
    "        int moduloFactor = numSplits/4096;\n",
    "        //Sub-partition in split i: (floor(i/s), i%s, s)\n",
    "        assignments = new SplitAssignment[numSplits];\n",
    "        for (int i = 0; i < numSplits; i++) {\n",
    "            QueryPartition qp = new QueryPartition((int)Math.floor((double)i/moduloFactor), 1, \n",
    "                                                    moduloFactor, i % moduloFactor, 1);\n",
    "            assignments[i] = new SplitAssignment(qp);\n",
    "        }\n",
    "    }\n",
    "    return assignments;\n",
    "}\n",
    "\n",
    "// the following function assigns exact number of splits that may be slightly different in size, but\n",
    "// each split data can be requested using a single API call (the client library may distribute \n",
    "// the request across multiple nodes). provided as another example, but we do not use it in the subsequent\n",
    "// runs.\n",
    "SplitAssignment[] assignExactSplitsSingleQuery(int reqSplits) {\n",
    "    int numSplits = 0;\n",
    "    SplitAssignment[] assignments = null;\n",
    "    if (reqSplits <= 4096) {\n",
    "        // Case 1: N <= 4096\n",
    "        // Each split is assigned full partitions only (maxModulo=1), \n",
    "        //.   with some may get an additional partition.\n",
    "        // Evenly assign partitions over N splits.\n",
    "        // Number of full partitions per split, n: floor(4096/N)\n",
    "        int minPartitionsPerSplit = (int)Math.floor((double)4096/reqSplits);\n",
    "        // Remaining partitions r are allocated in full to splits 0 to r-1\n",
    "        int remainingPartitions = 4096 - minPartitionsPerSplit*reqSplits;\n",
    "        // Assign minPartitionsPerSplit+1 to the first remainingPartitions splits, and\n",
    "        //   minPartitionsPerSplit to the rest.\n",
    "        int nextStartPartition = 0;\n",
    "        assignments = new SplitAssignment[reqSplits];\n",
    "        for (int i=0; i < reqSplits; i++){\n",
    "            if (i < remainingPartitions) {\n",
    "                QueryPartition qp = new QueryPartition(nextStartPartition, minPartitionsPerSplit+1);\n",
    "                assignments[i] = new SplitAssignment(qp);\n",
    "                nextStartPartition += minPartitionsPerSplit+1;\n",
    "            } else {\n",
    "                QueryPartition qp = new QueryPartition(nextStartPartition, minPartitionsPerSplit);\n",
    "                assignments[i] = new SplitAssignment(qp);\n",
    "                nextStartPartition += minPartitionsPerSplit;\n",
    "            }\n",
    "        }\n",
    "    } else {\n",
    "        // Case 2: N > 4096\n",
    "        // Each split is assigned one or two subpartitions in the same partition.\n",
    "        // Divide each partition into m (modulo-factor) subparittions: ceiling(N/4096) â€“ \n",
    "        //    the ceiling function ensures assignment across all N splits.\n",
    "        int moduloFactor = (int)Math.ceil((double)reqSplits/4096);\n",
    "        // 4096*moduloFactor sub-partitions are available to be assigned across reqSplits\n",
    "        // reqSplits sub-partitions are assigned one per split\n",
    "        // Remaining sub-partitions r = (4096*moduloFactor - reqSplits) are allocated to splits 0 to r-1.\n",
    "        int remainingSubPartitions = 4096*moduloFactor - reqSplits;\n",
    "        // Assign 2 sub-partitions to the first remainingSubPartitions splits while ensuring both\n",
    "        //.  sub-partitions are from the same partition, and 1 sub-partition to the rest.\n",
    "        int twoSubsSplitIndex = 0; // varies from 0 to remainingSubPartitions-1\n",
    "        int oneSubSplitIndex = remainingSubPartitions; // varies from remainingSubPartitions to reqSplits\n",
    "        assignments = new SplitAssignment[reqSplits];\n",
    "        for (int i=0; i < 4096; i++) {\n",
    "            int subPartition = 0;\n",
    "            while (subPartition < moduloFactor) {\n",
    "                if (twoSubsSplitIndex < remainingSubPartitions &&\n",
    "                        subPartition+1 < moduloFactor) { // both subpartitions must be in the same partition\n",
    "                    QueryPartition qp = new QueryPartition(i, 1, moduloFactor, subPartition, 2);\n",
    "                    assignments[twoSubsSplitIndex] = new SplitAssignment(qp);\n",
    "                    twoSubsSplitIndex++;\n",
    "                    subPartition += 2; \n",
    "                } else {\n",
    "                    // single partition assignment\n",
    "                    QueryPartition qp = new QueryPartition(i, 1, moduloFactor, subPartition, 1);\n",
    "                    assignments[oneSubSplitIndex] = new SplitAssignment(qp);\n",
    "                    oneSubSplitIndex++;\n",
    "                    subPartition++; \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return assignments;\n",
    "}\n",
    "\n",
    "// EXACT_SPLITS assigns exact number of splits of equal sizes.\n",
    "// The algorithm divides each of the 4096 partitions into num-splits number of subpartitions.\n",
    "// This results in 4096 * num-splits subpartitions, with each split getting 4096 subpartitions.\n",
    "// The 4096 subpartitions are enumerated from subpartition 0 to num-splits in partitions starting from \n",
    "// parttion 0  4096. Assignment for the next split starts after the last subpartion of the previous split.\n",
    "// Thus a split has subpartitions belonging in one or more of the following 3 groups, \n",
    "// each of which can be retrieved using one API call:  \n",
    "// 1. Consecutive 0-4095 subpartitions in the starting (partial) partition\n",
    "// 2. Consecutive 0-4096  full partitions\n",
    "// 3. Consecutive 0-4095 subpartitions in the ending (partial) partition\n",
    "SplitAssignment[] assignExactSplits(int reqSplits) {\n",
    "    SplitAssignment[] assignments = new SplitAssignment[reqSplits];\n",
    "    int nextSlot = 0;\n",
    "    for (int i=0; i < reqSplits; i++) {\n",
    "        int remaining = 4096;\n",
    "        boolean noneAssigned = true;\n",
    "        // 1. Consecutive 0-4095 subpartitions in the starting (partial) partition\n",
    "        int partition = nextSlot / reqSplits;\n",
    "        int sub = nextSlot % reqSplits;\n",
    "        if (sub + remaining > reqSplits && sub > 0) {\n",
    "            int subCount = reqSplits-sub;\n",
    "            QueryPartition qp = new QueryPartition(partition, 1, reqSplits, sub, subCount);\n",
    "            assignments[i] = new SplitAssignment(qp);\n",
    "            noneAssigned = false;\n",
    "            remaining -= subCount;\n",
    "            nextSlot += subCount;\n",
    "        }\n",
    "        // 2. Consecutive 0-4096 full partitions\n",
    "        partition = nextSlot / reqSplits;\n",
    "        sub = nextSlot % reqSplits;\n",
    "        assert(sub == 0 || sub + remaining <= reqSplits);\n",
    "        int count = 0;\n",
    "        while (remaining >= reqSplits) {\n",
    "            count++;\n",
    "            remaining -= reqSplits;\n",
    "            nextSlot += reqSplits;\n",
    "        }\n",
    "        if (count > 0) {\n",
    "            QueryPartition qp = new QueryPartition(partition, count);\n",
    "            if (noneAssigned) {\n",
    "                assignments[i] = new SplitAssignment(qp);        \n",
    "                noneAssigned = false;\n",
    "            } else {\n",
    "                assignments[i].add(qp);\n",
    "            }\n",
    "        }\n",
    "        // 3. Consecutive 0-4095 subpartitions in the ending (partial) partition\n",
    "        partition = nextSlot / reqSplits;\n",
    "        sub = nextSlot % reqSplits;\n",
    "        assert(sub + remaining <= reqSplits);\n",
    "        if (remaining > 0) {\n",
    "            QueryPartition qp = new QueryPartition(partition, 1, reqSplits, sub, remaining);\n",
    "            if (noneAssigned) {\n",
    "                assignments[i] = new SplitAssignment(qp);        \n",
    "                noneAssigned = false;\n",
    "            } else {\n",
    "                assignments[i].add(qp);\n",
    "            }\n",
    "            nextSlot += remaining;        \n",
    "            remaining = 0;\n",
    "        }\n",
    "    }\n",
    "    assert(nextSlot == reqSplits*4096);\n",
    "    return assignments;\n",
    "}\n",
    "\n",
    "// split assignment types:\n",
    "//       MAX_NUM_SPLITS At most requested number of splits (can be fewer), but same sized.\n",
    "//       MIN_NUM_SPLITS At least requested number of splits (can be more), but same sized\n",
    "//       EXACT_NUM_SPLITS_SINGLE_QUERY Exactly requested number of splits, can be different sized, \n",
    "//                              each processed in one query operation.\n",
    "//       EXACT_NUM_SPLITS Exactly requested number of splits, same sized, each split may be \n",
    "//                              processed in multiple API operations.\n",
    "SplitAssignment[] assignSplits(int reqSplits, int splitType) {\n",
    "    if (splitType == MAX_NUM_SPLITS) {\n",
    "        return assignMaxSplits(reqSplits);\n",
    "    } else if (splitType == MIN_NUM_SPLITS) {\n",
    "        return assignMinSplits(reqSplits);\n",
    "    } else if (splitType == EXACT_NUM_SPLITS) {\n",
    "        return assignExactSplits(reqSplits);\n",
    "    }\n",
    "    return null;\n",
    "}\n",
    "\n",
    "void assignmentSummary(String type, int reqSplits, SplitAssignment[] sa) {\n",
    "    System.out.format(\"Split type %s, requested %d, assigned %d (ends and middle): \\n\", type, reqSplits, sa.length);\n",
    "    List<Integer> sample = new ArrayList<Integer>();\n",
    "    sample.add(0);\n",
    "    if (sa.length > 1) sample.add(1);\n",
    "    if (sa.length > 4) sample.add(sa.length/2);\n",
    "    if (sa.length > 3) sample.add(sa.length-2);\n",
    "    if (sa.length > 2) sample.add(sa.length-1);\n",
    "    for (int i: sample) {\n",
    "        System.out.format(\"\\tSplit %s:\\n\", i);\n",
    "        for (QueryPartition qp: sa[i].queryPartitions) {\n",
    "            System.out.format(\"\\t\\tptn_start: %s, ptn_count: %s, sub_start: %s, sub_count: %s, sub_mod: %s\\n\", \n",
    "                        qp.startPartitionId, qp.partitionCount, qp.startSubpartitionId, qp.subpartitionCount, qp.subpartitionModuloFactor);\n",
    "        }\n",
    "    }   \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of Split Type Assignments\n",
    "Below are examples of split assignments for different number of splits and types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split type MAX_NUM_SPLITS, requested 5000, assigned 4096 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 1, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 1, ptn_count: 1, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 2048:\n",
      "\t\tptn_start: 2048, ptn_count: 1, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 4094:\n",
      "\t\tptn_start: 4094, ptn_count: 1, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 4095:\n",
      "\t\tptn_start: 4095, ptn_count: 1, sub_start: null, sub_count: null, sub_mod: null\n",
      "\n",
      "Split type MIN_NUM_SPLITS, requested 500, assigned 512 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 8, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 8, ptn_count: 8, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 256:\n",
      "\t\tptn_start: 2048, ptn_count: 8, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 510:\n",
      "\t\tptn_start: 4080, ptn_count: 8, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 511:\n",
      "\t\tptn_start: 4088, ptn_count: 8, sub_start: null, sub_count: null, sub_mod: null\n",
      "\n",
      "Split type EXACT_NUM_SPLITS, requested 3, assigned 3 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 1365, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 1365, ptn_count: 1, sub_start: 0, sub_count: 1, sub_mod: 3\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 1365, ptn_count: 1, sub_start: 1, sub_count: 2, sub_mod: 3\n",
      "\t\tptn_start: 1366, ptn_count: 1364, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 2730, ptn_count: 1, sub_start: 0, sub_count: 2, sub_mod: 3\n",
      "\tSplit 2:\n",
      "\t\tptn_start: 2730, ptn_count: 1, sub_start: 2, sub_count: 1, sub_mod: 3\n",
      "\t\tptn_start: 2731, ptn_count: 1365, sub_start: null, sub_count: null, sub_mod: null\n",
      "\n",
      "Split type EXACT_NUM_SPLITS, requested 100, assigned 100 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 40, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 40, ptn_count: 1, sub_start: 0, sub_count: 96, sub_mod: 100\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 40, ptn_count: 1, sub_start: 96, sub_count: 4, sub_mod: 100\n",
      "\t\tptn_start: 41, ptn_count: 40, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 81, ptn_count: 1, sub_start: 0, sub_count: 92, sub_mod: 100\n",
      "\tSplit 50:\n",
      "\t\tptn_start: 2048, ptn_count: 40, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 2088, ptn_count: 1, sub_start: 0, sub_count: 96, sub_mod: 100\n",
      "\tSplit 98:\n",
      "\t\tptn_start: 4014, ptn_count: 1, sub_start: 8, sub_count: 92, sub_mod: 100\n",
      "\t\tptn_start: 4015, ptn_count: 40, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 4055, ptn_count: 1, sub_start: 0, sub_count: 4, sub_mod: 100\n",
      "\tSplit 99:\n",
      "\t\tptn_start: 4055, ptn_count: 1, sub_start: 4, sub_count: 96, sub_mod: 100\n",
      "\t\tptn_start: 4056, ptn_count: 40, sub_start: null, sub_count: null, sub_mod: null\n",
      "\n",
      "Split type EXACT_NUM_SPLITS, requested 1000, assigned 1000 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 4, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 4, ptn_count: 1, sub_start: 0, sub_count: 96, sub_mod: 1000\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 4, ptn_count: 1, sub_start: 96, sub_count: 904, sub_mod: 1000\n",
      "\t\tptn_start: 5, ptn_count: 3, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 8, ptn_count: 1, sub_start: 0, sub_count: 192, sub_mod: 1000\n",
      "\tSplit 500:\n",
      "\t\tptn_start: 2048, ptn_count: 4, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 2052, ptn_count: 1, sub_start: 0, sub_count: 96, sub_mod: 1000\n",
      "\tSplit 998:\n",
      "\t\tptn_start: 4087, ptn_count: 1, sub_start: 808, sub_count: 192, sub_mod: 1000\n",
      "\t\tptn_start: 4088, ptn_count: 3, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 4091, ptn_count: 1, sub_start: 0, sub_count: 904, sub_mod: 1000\n",
      "\tSplit 999:\n",
      "\t\tptn_start: 4091, ptn_count: 1, sub_start: 904, sub_count: 96, sub_mod: 1000\n",
      "\t\tptn_start: 4092, ptn_count: 4, sub_start: null, sub_count: null, sub_mod: null\n",
      "\n",
      "Split type EXACT_NUM_SPLITS, requested 4096, assigned 4096 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 1, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 1, ptn_count: 1, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 2048:\n",
      "\t\tptn_start: 2048, ptn_count: 1, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 4094:\n",
      "\t\tptn_start: 4094, ptn_count: 1, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 4095:\n",
      "\t\tptn_start: 4095, ptn_count: 1, sub_start: null, sub_count: null, sub_mod: null\n",
      "\n",
      "Split type EXACT_NUM_SPLITS, requested 10000, assigned 10000 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 1, sub_start: 0, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 0, ptn_count: 1, sub_start: 4096, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 5000:\n",
      "\t\tptn_start: 2048, ptn_count: 1, sub_start: 0, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 9998:\n",
      "\t\tptn_start: 4095, ptn_count: 1, sub_start: 1808, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 9999:\n",
      "\t\tptn_start: 4095, ptn_count: 1, sub_start: 5904, sub_count: 4096, sub_mod: 10000\n"
     ]
    }
   ],
   "source": [
    "SplitAssignment[] sa = assignSplits(5000, MAX_NUM_SPLITS);\n",
    "assignmentSummary(\"MAX_NUM_SPLITS\", 5000, sa);\n",
    "System.out.println();\n",
    "\n",
    "sa = assignSplits(500, MIN_NUM_SPLITS);\n",
    "assignmentSummary(\"MIN_NUM_SPLITS\", 500, sa);\n",
    "System.out.println();\n",
    "\n",
    "sa = assignSplits(3, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(\"EXACT_NUM_SPLITS\", 3, sa);\n",
    "System.out.println();\n",
    "\n",
    "sa = assignSplits(100, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(\"EXACT_NUM_SPLITS\", 100, sa);\n",
    "System.out.println();\n",
    "\n",
    "sa = assignSplits(1000, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(\"EXACT_NUM_SPLITS\", 1000, sa);\n",
    "System.out.println();\n",
    "\n",
    "sa = assignSplits(4096, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(\"EXACT_NUM_SPLITS\", 4096, sa);\n",
    "System.out.println();\n",
    "\n",
    "sa = assignSplits(10000, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(\"EXACT_NUM_SPLITS\", 10000, sa);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Query Framework\n",
    "The parallel processing test framework works as follows:\n",
    "- Create N splits. This can be varied over a wide range such as 1-50K, along with the type  AtLeast, AtMost, and Exact.\n",
    "- Spawn W worker threads. This can be varied over a wide range such as 1-5K or more if the setup allows it. All threads start processing splits at the same time, and the main thread waits until all threads finish.\n",
    "- A worker executes a loop:\n",
    "    - While threre is an unprocessed split available:\n",
    "        - Get a split from the available splits.\n",
    "        - Process the split:\n",
    "            - While there are more records to be processed in the split, in sync and async mode:\n",
    "                - Execute a query to retrieve the next chunk of max-records. The query can be a primary-index query or a secondary-index query, and with or without a fiter expression.\n",
    "                - Process the chunk using the provided implementation of StreamProcessing abstract class. A simple CountAndSum implementation is used.\n",
    "- The total record count and aggregate sum is printed out at the end, which should be the same for a given query and filter expression\n",
    "\n",
    "The code below implements the parallel processing framework that allows interesting parameters to be selected for each run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Processing: Aggregate Computation\n",
    "The framework processes the records retrieved through a parallel query over splits with a map-reduce computation. A simple count-and-sum computation is used, but can be substituted with another computation by overriding the abstract class StreamProcessing, and providing the class instance in the global StreamProcessor (defined below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "// A simple SplitsProcessor abstract class - must provide implementation\n",
    "abstract class StreamProcessing {\n",
    "    abstract void initialize(int numStreams);\n",
    "    abstract void processRecordSet(int splitId, RecordSet rs);\n",
    "    abstract void processRecord(int splitId, Record rec);\n",
    "    abstract void finish();\n",
    "    abstract void printResults();\n",
    "}\n",
    "\n",
    "// \n",
    "class CountAndSum extends StreamProcessing {\n",
    "    AtomicInteger[] streamCounts;\n",
    "    AtomicLong[] streamSums;\n",
    "    CountAndSum() {};  \n",
    "    void initialize(int numStreams) {\n",
    "        this.streamCounts = new AtomicInteger[numStreams+1]; //final aggregation uses the last slot\n",
    "        this.streamSums = new AtomicLong[numStreams+1]; //final aggregation uses the last slot\n",
    "        for (int i=0; i < numStreams+1; i++) {\n",
    "            this.streamCounts[i] = new AtomicInteger(0);\n",
    "            this.streamSums[i] = new AtomicLong(0);\n",
    "        }\n",
    "    }\n",
    "    void processRecordSet(int streamId, RecordSet rs) {\n",
    "        int recs = 0;\n",
    "        long sum = 0;\n",
    "        try {\n",
    "            while (rs.next()) {\n",
    "                recs++;\n",
    "                Record rec = rs.getRecord();\n",
    "                sum += (long)rec.bins.get(\"bin1\");             \n",
    "            }\n",
    "        }\n",
    "        finally {\n",
    "            rs.close();\n",
    "        }  \n",
    "        this.streamCounts[streamId].addAndGet(recs);\n",
    "        this.streamSums[streamId].addAndGet(sum);\n",
    "    }\n",
    "    void processRecord(int streamId, Record rec) {\n",
    "        this.streamCounts[streamId].incrementAndGet();\n",
    "        this.streamSums[streamId].addAndGet((long)rec.bins.get(\"bin1\"));    \n",
    "    }\n",
    "    void finish() {\n",
    "        // aggregste results in the final slot\n",
    "        int resultsSlot = this.streamCounts.length-1;\n",
    "        for (int i=0; i < this.streamCounts.length-1; i++) {\n",
    "            this.streamCounts[resultsSlot].addAndGet(this.streamCounts[i].get());\n",
    "            this.streamSums[resultsSlot].addAndGet(this.streamSums[i].get());\n",
    "        }\n",
    "    }\n",
    "    void printResults() {\n",
    "        // print results from the final slot\n",
    "        int resultsSlot = this.streamCounts.length-1;\n",
    "        System.out.format(\"Record count is %d, sum is %d.\\n\", \n",
    "                            this.streamCounts[resultsSlot].get(),this.streamSums[resultsSlot].get());\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Scheduling: Next Available Split\n",
    "The framework assigns the next split for a worker to process from the available splits. A simple next-available  computation is used, but can be substituted with another scheduler by overriding the abstract class WorkScheduling, and providing the class instance in the global WorkScheduler (defined below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "// A simple WorkScheduling abstract class - must provide implementation\n",
    "abstract class WorkScheduling {\n",
    "    abstract void initialize(int numWorkers, int numSplits);\n",
    "    abstract Integer scheduleSplit(int workerId);\n",
    "}\n",
    "\n",
    "// \n",
    "class NextAvailable extends WorkScheduling {\n",
    "    int numSplits;\n",
    "    AtomicInteger nextAvailable = new AtomicInteger(0);\n",
    "    NextAvailable() {};  \n",
    "    void initialize(int numWorkers, int numSplits) {\n",
    "        this.numSplits = numSplits;\n",
    "        nextAvailable.set(0);\n",
    "    }\n",
    "    Integer scheduleSplit(int workerId) {\n",
    "        if (this.nextAvailable.get() >= numSplits) {\n",
    "            return null;\n",
    "        }\n",
    "        int splitToSchedule = this.nextAvailable.getAndIncrement();\n",
    "        if (splitToSchedule >= numSplits) {\n",
    "            return null;\n",
    "        }\n",
    "        return splitToSchedule;\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters\n",
    "The following parameters are implemented as global variables for convenience. They can be set to appropriate desired values before a run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Global parameters - set to specific values later before a run\n",
    "int ProcessingMode;     // set to PROCESSING_MODE_SYNC or PROCESSING_MODE_ASYNC\n",
    "int QueryType;          // PRIMARY_INDEX_QUERY or SECONDARY_INDEX_QUERY\n",
    "int QueryFilter;        // QUERY_FILTER_NONE or QUERY_FILTER_INCLUDE\n",
    "int ChunkSize;          // max number of records retrieved in a chunk\n",
    "Filter SecondaryIndexQueryPredicate; // sindex query predicate, used when QueryType = SECONDARY_INDEX_QUERY\n",
    "Exp IncludeQueryFilterExp; // filter expression, used when QueryFilter = QUERY_FILTER_INCLUDE\n",
    "StreamProcessing StreamProcessor; // computation over streams\n",
    "WorkScheduling WorkScheduler; // schedule the next split to a worker\n",
    "// define default for StreamProcessor; can be redefined/\n",
    "StreamProcessor = new CountAndSum();\n",
    "// define default for WorkScheduler; can be redefined/\n",
    "WorkScheduler = new NextAvailable();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Implementation of the parallel query framework\n",
    "\n",
    "CountDownLatch startLineLatch;                   // forces all workers to start at the same time\n",
    "\n",
    "Statement stmt = new Statement();\n",
    "stmt.setNamespace(Namespace);\n",
    "stmt.setSetName(Set);\n",
    "stmt.setBinNames(\"bin1\", \"bin2\");\n",
    "\n",
    "class Worker extends Thread {\n",
    "    static AtomicInteger nextWorkerId = new AtomicInteger();    // worker id\n",
    "    static SplitAssignment[] assignments; // splits to be processed\n",
    "    \n",
    "    static void initialize(int numWorkers, SplitAssignment[] splitAssignments) {\n",
    "        Worker.nextWorkerId.set(0);\n",
    "        Worker.assignments = splitAssignments;\n",
    "        WorkScheduler.initialize(numWorkers, splitAssignments.length);\n",
    "    }\n",
    "\n",
    "    @Override public void run() {\n",
    "        int myId = Worker.nextWorkerId.getAndIncrement();    \n",
    "        try {\n",
    "            startLineLatch.countDown(); // count down\n",
    "            startLineLatch.await();     // all workers start when count reaches zero\n",
    "        }\n",
    "        catch (Exception e) {\n",
    "           System.out.format(\"%s\", e);\n",
    "        }\n",
    "        //System.out.println(Thread.currentThread().getName()\n",
    "        //            + \": \" + myId);\n",
    "        int numSplits = Worker.assignments.length;\n",
    "        // loop to get the next available split until all splits are claimed\n",
    "        for (Integer split = WorkScheduler.scheduleSplit(myId); split != null; \n",
    "                                                        split = WorkScheduler.scheduleSplit(myId)) {\n",
    "            SplitAssignment sa = Worker.assignments[split]; // split to process\n",
    "            for (QueryPartition qp: sa.queryPartitions) {\n",
    "                PartitionFilter pFilter;\n",
    "                QueryPolicy qPolicy = new QueryPolicy(client.queryPolicyDefault);\n",
    "                qPolicy.socketTimeout = 120000; // 2 min\n",
    "                qPolicy.maxRetries = 0; // do not retry\n",
    "\n",
    "                qPolicy.filterExp = null;\n",
    "                // define the query partition filter\n",
    "                pFilter = PartitionFilter.range(qp.startPartitionId, qp.partitionCount); // assign the partition range\n",
    "                if (qp.isFullPartitionAssignment) {  \n",
    "                    if (QueryFilter == QUERY_FILTER_INCLUDE) { \n",
    "                        qPolicy.filterExp = Exp.build(IncludeQueryFilterExp);\n",
    "                    }\n",
    "                } else { // if partial partitions, define the digest-modulo filter expression\n",
    "                    int moduloFactor = qp.subpartitionModuloFactor;\n",
    "                    int lowerSubpartition = qp.startSubpartitionId;\n",
    "                    int upperSubpartition = lowerSubpartition + qp.subpartitionCount - 1;\n",
    "                    Exp subpartitionExp = Exp.and(\n",
    "                                            Exp.ge(Exp.digestModulo(moduloFactor), Exp.val(lowerSubpartition)), \n",
    "                                            Exp.le(Exp.digestModulo(moduloFactor), Exp.val(upperSubpartition)));\n",
    "                    Exp queryFilterExp = subpartitionExp;\n",
    "                    if (QueryFilter == QUERY_FILTER_INCLUDE) { // AND with the query's filter expression\n",
    "                        queryFilterExp = Exp.and(\n",
    "                                            subpartitionExp,\n",
    "                                            IncludeQueryFilterExp);\n",
    "                    }\n",
    "                    qPolicy.filterExp = Exp.build(queryFilterExp); //  filter expression is specified in policy\n",
    "                }\n",
    "                stmt.setMaxRecords(ChunkSize);  // chunked retrieval of query results \n",
    "                stmt.setFilter(null);            // this query filter is null for a primary-index query\n",
    "                if (QueryType == SECONDARY_INDEX_QUERY) {\n",
    "                    stmt.setFilter(SecondaryIndexQueryPredicate); // set secondary-index query predicate here\n",
    "                }\n",
    "                if (ProcessingMode == PROCESSING_MODE_SYNC) { // select the processing mode\n",
    "                    this.processSync(myId, qPolicy, stmt, pFilter); \n",
    "                } else {\n",
    "                    this.processAsync(myId, qPolicy, stmt, pFilter);\n",
    "                }\n",
    "                try {\n",
    "                    Thread.sleep(1); // allow other threads to run\n",
    "                }\n",
    "                catch (Exception e) {\n",
    "                   System.out.format(\"%s\", e);\n",
    "                }            \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    void processSync(int workerId, QueryPolicy qPolicy, Statement stmt, PartitionFilter pFilter) {\n",
    "        // retrieve chunks of records in a loop\n",
    "        while (! pFilter.isDone()) {\n",
    "            RecordSet rs = client.queryPartitions(qPolicy, stmt, pFilter);\n",
    "            StreamProcessor.processRecordSet(workerId, rs);\n",
    "        }\n",
    "    }\n",
    "        \n",
    "    void processAsync(int workerId, QueryPolicy qPolicy, Statement stmt, PartitionFilter pFilter) {\n",
    "        // Query all pages of records.\n",
    "        while (! pFilter.isDone()) {\n",
    "            // query monitor to await/notify completion of each chunk\n",
    "            Monitor queryMonitor = new Monitor();\n",
    "            // submit async operation with throttle by waiting for an available slot\n",
    "            EventLoop eventLoop = eventLoops.next();\n",
    "            int eventLoopIndex = eventLoop.getIndex();\n",
    "            if (throttles.waitForSlot(eventLoopIndex, 1)) { \n",
    "                try {\n",
    "                    client.queryPartitions(eventLoop, new RecordSequenceListener() {\n",
    "                            public void onRecord(Key key, Record record) throws AerospikeException {\n",
    "                                StreamProcessor.processRecord(workerId, record);\n",
    "                             }\n",
    "                             \n",
    "                            public void onSuccess() {\n",
    "                                throttles.addSlot(eventLoopIndex, 1);\n",
    "                                queryMonitor.notifyComplete();\n",
    "                            }\n",
    "\n",
    "                            public void onFailure(AerospikeException e) {\n",
    "                                throttles.addSlot(eventLoopIndex, 1);\n",
    "                                System.out.format(\"Error: query failed with exception - %s\", e);\n",
    "                                queryMonitor.notifyComplete();\n",
    "                            }                    \n",
    "                        }, \n",
    "                        qPolicy, stmt, pFilter);\n",
    "                }\n",
    "                catch (Exception e) {\n",
    "                   System.out.format(\"Error: exception in record sequence listener - %s\\n\", e.getMessage());\n",
    "                }\n",
    "            }\n",
    "            queryMonitor.waitTillComplete();\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "void workerSummary() {\n",
    "    System.out.print(\"Records by worker (~50 worker sample): \");\n",
    "    float step = (((CountAndSum)StreamProcessor).streamCounts.length-2)/50;\n",
    "    for (int i = 0; i < ((CountAndSum)StreamProcessor).streamCounts.length-1; i += 1+step) {\n",
    "        System.out.format(\"%d:%d \", i, ((CountAndSum)StreamProcessor).streamCounts[i].get());\n",
    "    }\n",
    "    System.out.println(\"\");\n",
    "}\n",
    "\n",
    "void processSplits(SplitAssignment[] splitAssignments, int numWorkers) {\n",
    "    System.out.format(\"%d worker threads.\\n\", numWorkers);\n",
    "    StreamProcessor.initialize(numWorkers);\n",
    "    Worker.initialize(numWorkers, splitAssignments);\n",
    "    startLineLatch = new CountDownLatch(numWorkers);\n",
    "    List<Worker> workers = new ArrayList<>();\n",
    "    for (int i = 0; i < numWorkers; i++) {\n",
    "        Worker worker = new Worker();\n",
    "        worker.setName(\"Worker \" + i);\n",
    "        workers.add(worker);\n",
    "        worker.start();\n",
    "    }\n",
    "    // workers don't start work until all workers are spawned\n",
    "    long startTime = System.currentTimeMillis();\n",
    "    try {\n",
    "        // wait for all workers to finish\n",
    "        for (Worker worker: workers) {\n",
    "            worker.join();\n",
    "        }\n",
    "    }\n",
    "    catch (Exception e) {\n",
    "       System.out.format(\"%s\", e);\n",
    "    }\n",
    "    long endTime = System.currentTimeMillis();\n",
    "    StreamProcessor.finish();\n",
    "    StreamProcessor.printResults();\n",
    "    //System.out.format(\"Record count is %d, sum is %d.\\n\", recCount.get(), recSum.get());\n",
    "    System.out.println(\"That took \" + (endTime - startTime)/1000 + \" seconds.\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Runs\n",
    "We will establish the baseline with these parameters:\n",
    "- Single worker\n",
    "- Chunk size 100 and unlimited (100000)\n",
    "- Secondary query and equivalent filter\n",
    "- Sync and async modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: 1, type: EXACT_NUM_SPLITS, chunk size: 50, query type: scan w/o filter, mode: SYNC\n",
      "1 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 29 seconds.\n",
      "\n",
      "Splits: 1, type: EXACT_NUM_SPLITS, chunk size: 100000, query type: scan w/o filter, mode: SYNC\n",
      "1 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 0 seconds.\n",
      "\n",
      "Splits: 1, type: EXACT_NUM_SPLITS, chunk size: 50, query type: scan with filter, mode: SYNC\n",
      "1 worker threads.\n",
      "Record count is 50000, sum is 2500025000.\n",
      "That took 21 seconds.\n",
      "\n",
      "Splits: 1, type: EXACT_NUM_SPLITS, chunk size: 50, query type: sindex query, mode: SYNC\n",
      "1 worker threads.\n",
      "Record count is 50000, sum is 2500025000.\n",
      "That took 9 seconds.\n",
      "\n",
      "Splits: 1, type: EXACT_NUM_SPLITS, chunk size: 50, query type: scan w/o filter, mode: ASYNC\n",
      "1 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 25 seconds.\n",
      "\n",
      "Splits: 1, type: EXACT_NUM_SPLITS, chunk size: 100000, query type: scan w/o filter, mode: ASYNC\n",
      "1 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 0 seconds.\n",
      "\n",
      "Splits: 1, type: EXACT_NUM_SPLITS, chunk size: 50, query type: scan with filter, mode: ASYNC\n",
      "1 worker threads.\n",
      "Record count is 50000, sum is 2500025000.\n",
      "That took 21 seconds.\n",
      "\n",
      "Splits: 1, type: EXACT_NUM_SPLITS, chunk size: 50, query type: sindex query, mode: ASYNC\n",
      "1 worker threads.\n",
      "Record count is 50000, sum is 2500025000.\n",
      "That took 9 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Equivalent sseconday-index and filter predicates\n",
    "IncludeQueryFilterExp = Exp.and(Exp.ge(Exp.intBin(\"bin1\"), Exp.val(25001)), Exp.le(Exp.intBin(\"bin1\"), Exp.val(75000)));\n",
    "SecondaryIndexQueryPredicate = Filter.range(\"bin1\", 25001, 75000);\n",
    "\n",
    "int numSplits = 1;\n",
    "int numWorkers = 1;\n",
    "ProcessingMode = PROCESSING_MODE_SYNC;\n",
    "ChunkSize = 50;\n",
    "QueryFilter = QUERY_FILTER_NONE;\n",
    "QueryType = PRIMARY_INDEX_QUERY;\n",
    "\n",
    "System.out.format(\"Splits: %d, type: %s, chunk size: %s, query type: %s, mode: %s\\n\", \n",
    "                            numSplits, \"EXACT_NUM_SPLITS\", ChunkSize, \"scan w/o filter\", \"SYNC\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(numSplits, EXACT_NUM_SPLITS);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n",
    "\n",
    "ChunkSize = 100000;\n",
    "System.out.format(\"Splits: %d, type: %s, chunk size: %s, query type: %s, mode: %s\\n\", \n",
    "                            numSplits, \"EXACT_NUM_SPLITS\", ChunkSize, \"scan w/o filter\", \"SYNC\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(numSplits, EXACT_NUM_SPLITS);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n",
    "\n",
    "ChunkSize = 50;\n",
    "QueryFilter = QUERY_FILTER_INCLUDE;\n",
    "System.out.format(\"Splits: %d, type: %s, chunk size: %s, query type: %s, mode: %s\\n\", \n",
    "                            numSplits, \"EXACT_NUM_SPLITS\", ChunkSize, \"scan with filter\", \"SYNC\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(numSplits, EXACT_NUM_SPLITS);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n",
    "\n",
    "QueryFilter = QUERY_FILTER_NONE;\n",
    "QueryType = SECONDARY_INDEX_QUERY;\n",
    "System.out.format(\"Splits: %d, type: %s, chunk size: %s, query type: %s, mode: %s\\n\", \n",
    "                            numSplits, \"EXACT_NUM_SPLITS\", ChunkSize, \"sindex query\", \"SYNC\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(numSplits, EXACT_NUM_SPLITS);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_ASYNC;\n",
    "ChunkSize = 50;\n",
    "QueryFilter = QUERY_FILTER_NONE;\n",
    "QueryType = PRIMARY_INDEX_QUERY;\n",
    "System.out.format(\"Splits: %d, type: %s, chunk size: %s, query type: %s, mode: %s\\n\", \n",
    "                            numSplits, \"EXACT_NUM_SPLITS\", ChunkSize, \"scan w/o filter\", \"ASYNC\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(numSplits, EXACT_NUM_SPLITS);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n",
    "\n",
    "ChunkSize = 100000;\n",
    "System.out.format(\"Splits: %d, type: %s, chunk size: %s, query type: %s, mode: %s\\n\", \n",
    "                            numSplits, \"EXACT_NUM_SPLITS\", ChunkSize, \"scan w/o filter\", \"ASYNC\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(numSplits, EXACT_NUM_SPLITS);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n",
    "\n",
    "ChunkSize = 50;\n",
    "QueryFilter = QUERY_FILTER_INCLUDE;\n",
    "System.out.format(\"Splits: %d, type: %s, chunk size: %s, query type: %s, mode: %s\\n\", \n",
    "                            numSplits, \"EXACT_NUM_SPLITS\", ChunkSize, \"scan with filter\", \"ASYNC\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(numSplits, EXACT_NUM_SPLITS);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n",
    "\n",
    "QueryFilter = QUERY_FILTER_NONE;\n",
    "QueryType = SECONDARY_INDEX_QUERY;\n",
    "System.out.format(\"Splits: %d, type: %s, chunk size: %s, query type: %s, mode: %s\\n\", \n",
    "                            numSplits, \"EXACT_NUM_SPLITS\", ChunkSize, \"sindex query\", \"ASYNC\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(numSplits, EXACT_NUM_SPLITS);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Parallel Queries with Interesting Parameter Variations\n",
    "The key things to note are:\n",
    "- Split assignments - a summary can be printed out optionally as seen below.\n",
    "- Number of records and aggregated sum should be the same for the same query/filter setting, confirming all records are processed correctly.\n",
    "- Performance indicated by the time it took to execute a query\n",
    "- Distribution of records processed by worker - a summary can be printed out optionally as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "// set the base global parameter values - can be changed here or before a run in the cells below\n",
    "ProcessingMode = PROCESSING_MODE_SYNC;\n",
    "QueryType = PRIMARY_INDEX_QUERY;\n",
    "QueryFilter = QUERY_FILTER_NONE;\n",
    "ChunkSize = 30;\n",
    "\n",
    "// the following filter expression chooses records with even values of bin1 - CAN CHANGE TO A DIFFERENT EXPRESSION\n",
    "//    used when QueryFilter = QUERY_FILTER_INCLUDE\n",
    "IncludeQueryFilterExp = Exp.eq(Exp.mod(Exp.intBin(\"bin1\"), Exp.val(2)), Exp.val(0));\n",
    "\n",
    "// the following query predicate is a range filter for records with 50001 <= bin1 <= 100000 - CAN CHANGE TO A DIFFERENT QUERY PREDICATE\n",
    "//    used when QueryType = SECONDARY_INDEX_QUERY\n",
    "SecondaryIndexQueryPredicate = Filter.range(\"bin1\", 25001, 75000);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying number of splits and split types\n",
    "Vary the number of splits from 1-50000 acoss all split types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested splits: 2, type: MIN_NUM_SPLITS\n",
      "Split type MIN_NUM_SPLITS, requested 2, assigned 2 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 2048, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 2048, ptn_count: 2048, sub_start: null, sub_count: null, sub_mod: null\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 22 seconds.\n",
      "\n",
      "Requested splits: 10, type: MIN_NUM_SPLITS\n",
      "Split type MIN_NUM_SPLITS, requested 10, assigned 16 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 256, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 256, ptn_count: 256, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 8:\n",
      "\t\tptn_start: 2048, ptn_count: 256, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 14:\n",
      "\t\tptn_start: 3584, ptn_count: 256, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 15:\n",
      "\t\tptn_start: 3840, ptn_count: 256, sub_start: null, sub_count: null, sub_mod: null\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 3 seconds.\n",
      "\n",
      "Requested splits: 100, type: EXACT_NUM_SPLITS\n",
      "Split type EXACT_NUM_SPLITS, requested 100, assigned 100 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 40, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 40, ptn_count: 1, sub_start: 0, sub_count: 96, sub_mod: 100\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 40, ptn_count: 1, sub_start: 96, sub_count: 4, sub_mod: 100\n",
      "\t\tptn_start: 41, ptn_count: 40, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 81, ptn_count: 1, sub_start: 0, sub_count: 92, sub_mod: 100\n",
      "\tSplit 50:\n",
      "\t\tptn_start: 2048, ptn_count: 40, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 2088, ptn_count: 1, sub_start: 0, sub_count: 96, sub_mod: 100\n",
      "\tSplit 98:\n",
      "\t\tptn_start: 4014, ptn_count: 1, sub_start: 8, sub_count: 92, sub_mod: 100\n",
      "\t\tptn_start: 4015, ptn_count: 40, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 4055, ptn_count: 1, sub_start: 0, sub_count: 4, sub_mod: 100\n",
      "\tSplit 99:\n",
      "\t\tptn_start: 4055, ptn_count: 1, sub_start: 4, sub_count: 96, sub_mod: 100\n",
      "\t\tptn_start: 4056, ptn_count: 40, sub_start: null, sub_count: null, sub_mod: null\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 2 seconds.\n",
      "Records by worker (~50 worker sample): 0:1008 2:1016 4:1057 6:1040 8:995 10:986 12:1019 14:959 16:1003 18:962 20:1020 22:989 24:1016 26:1016 28:1018 30:1053 32:953 34:1002 36:969 38:1025 40:1036 42:986 44:920 46:970 48:898 50:1089 52:995 54:1003 56:1021 58:1033 60:1026 62:1024 64:1030 66:1040 68:1033 70:1051 72:1012 74:943 76:1009 78:1058 80:992 82:1042 84:968 86:1061 88:989 90:976 92:948 94:985 96:1007 98:1008 \n",
      "\n",
      "Requested splits: 1000, type: MAX_NUM_SPLITS\n",
      "Split type MAX_NUM_SPLITS, requested 1000, assigned 512 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 8, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 8, ptn_count: 8, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 256:\n",
      "\t\tptn_start: 2048, ptn_count: 8, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 510:\n",
      "\t\tptn_start: 4080, ptn_count: 8, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 511:\n",
      "\t\tptn_start: 4088, ptn_count: 8, sub_start: null, sub_count: null, sub_mod: null\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 1 seconds.\n",
      "Records by worker (~50 worker sample): 0:1020 2:1001 4:988 6:949 8:933 10:995 12:1123 14:1058 16:966 18:996 20:954 22:978 24:1110 26:1001 28:998 30:959 32:941 34:809 36:993 38:998 40:968 42:946 44:1066 46:1176 48:961 50:977 52:952 54:996 56:978 58:1146 60:1140 62:939 64:930 66:1013 68:999 70:978 72:1050 74:965 76:946 78:1152 80:1037 82:980 84:978 86:959 88:943 90:974 92:1013 94:944 96:988 98:990 \n",
      "\n",
      "Requested splits: 5000, type: MAX_NUM_SPLITS\n",
      "Split type MAX_NUM_SPLITS, requested 5000, assigned 4096 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 1, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 1, ptn_count: 1, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 2048:\n",
      "\t\tptn_start: 2048, ptn_count: 1, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 4094:\n",
      "\t\tptn_start: 4094, ptn_count: 1, sub_start: null, sub_count: null, sub_mod: null\n",
      "\tSplit 4095:\n",
      "\t\tptn_start: 4095, ptn_count: 1, sub_start: null, sub_count: null, sub_mod: null\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 2 seconds.\n",
      "Records by worker (~50 worker sample): 0:954 2:952 4:1057 6:1029 8:1053 10:1084 12:1041 14:999 16:988 18:1022 20:1051 22:965 24:1014 26:1020 28:1034 30:965 32:1010 34:1046 36:1041 38:979 40:1110 42:976 44:975 46:1028 48:987 50:1017 52:1069 54:1086 56:1031 58:1054 60:938 62:1121 64:901 66:935 68:1068 70:998 72:997 74:970 76:987 78:1022 80:907 82:938 84:1004 86:921 88:930 90:1015 92:1047 94:1004 96:891 98:848 \n",
      "\n",
      "Requested splits: 10000, type: EXACT_NUM_SPLITS\n",
      "Split type EXACT_NUM_SPLITS, requested 1000, assigned 10000 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 1, sub_start: 0, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 0, ptn_count: 1, sub_start: 4096, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 5000:\n",
      "\t\tptn_start: 2048, ptn_count: 1, sub_start: 0, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 9998:\n",
      "\t\tptn_start: 4095, ptn_count: 1, sub_start: 1808, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 9999:\n",
      "\t\tptn_start: 4095, ptn_count: 1, sub_start: 5904, sub_count: 4096, sub_mod: 10000\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 5 seconds.\n",
      "Records by worker (~50 worker sample): 0:1051 2:969 4:998 6:1027 8:1077 10:1037 12:994 14:1039 16:1043 18:1011 20:993 22:997 24:916 26:958 28:980 30:971 32:935 34:1018 36:908 38:958 40:1022 42:1075 44:1018 46:940 48:1140 50:919 52:1048 54:1030 56:931 58:928 60:1013 62:978 64:992 66:951 68:901 70:997 72:964 74:1046 76:1112 78:951 80:1024 82:1139 84:1007 86:1029 88:936 90:991 92:1077 94:927 96:994 98:1057 \n",
      "\n",
      "Requested splits: 50000, type: MAX_NUM_SPLITS\n",
      "Split type MAX_NUM_SPLITS, requested 50000, assigned 49152 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 1, sub_start: 0, sub_count: 1, sub_mod: 12\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 0, ptn_count: 1, sub_start: 1, sub_count: 1, sub_mod: 12\n",
      "\tSplit 24576:\n",
      "\t\tptn_start: 2048, ptn_count: 1, sub_start: 0, sub_count: 1, sub_mod: 12\n",
      "\tSplit 49150:\n",
      "\t\tptn_start: 4095, ptn_count: 1, sub_start: 10, sub_count: 1, sub_mod: 12\n",
      "\tSplit 49151:\n",
      "\t\tptn_start: 4095, ptn_count: 1, sub_start: 11, sub_count: 1, sub_mod: 12\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 20 seconds.\n",
      "Records by worker (~50 worker sample): 0:1023 2:979 4:988 6:1008 8:1062 10:995 12:971 14:1017 16:963 18:1030 20:1040 22:1002 24:985 26:962 28:1064 30:1014 32:1091 34:1008 36:979 38:948 40:976 42:1033 44:951 46:1044 48:1002 50:999 52:998 54:989 56:982 58:1005 60:1077 62:946 64:1031 66:965 68:941 70:1025 72:1005 74:975 76:1017 78:1016 80:1000 82:995 84:959 86:1017 88:996 90:1011 92:972 94:1002 96:1054 98:943 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "int NumWorkers = 100;\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 2, \"MIN_NUM_SPLITS\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(2, MIN_NUM_SPLITS);\n",
    "assignmentSummary(\"MIN_NUM_SPLITS\", 2, splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 10, \"MIN_NUM_SPLITS\");\n",
    "splitAssignments = assignSplits(10, MIN_NUM_SPLITS);\n",
    "assignmentSummary(\"MIN_NUM_SPLITS\", 10, splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 100, \"EXACT_NUM_SPLITS\");\n",
    "splitAssignments = assignSplits(100, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(\"EXACT_NUM_SPLITS\", 100, splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 1000, \"MAX_NUM_SPLITS\");\n",
    "splitAssignments = assignSplits(1000, MAX_NUM_SPLITS);\n",
    "assignmentSummary(\"MAX_NUM_SPLITS\", 1000, splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 5000, \"MAX_NUM_SPLITS\");\n",
    "splitAssignments = assignSplits(5000, MAX_NUM_SPLITS);\n",
    "assignmentSummary(\"MAX_NUM_SPLITS\", 5000, splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 10000, \"EXACT_NUM_SPLITS\");\n",
    "splitAssignments = assignSplits(10000, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(\"EXACT_NUM_SPLITS\", 1000, splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 50000, \"MAX_NUM_SPLITS\");\n",
    "splitAssignments = assignSplits(50000, MAX_NUM_SPLITS);\n",
    "assignmentSummary(\"MAX_NUM_SPLITS\", 50000, splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "workerSummary();\n",
    "System.out.println();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying number of workers in sync mode\n",
    "Vary the number of workers from 10 to 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split type EXACT_NUM_SPLITS, requested 10000, assigned 10000 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 1, sub_start: 0, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 0, ptn_count: 1, sub_start: 4096, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 5000:\n",
      "\t\tptn_start: 2048, ptn_count: 1, sub_start: 0, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 9998:\n",
      "\t\tptn_start: 4095, ptn_count: 1, sub_start: 1808, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 9999:\n",
      "\t\tptn_start: 4095, ptn_count: 1, sub_start: 5904, sub_count: 4096, sub_mod: 10000\n",
      "10 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 6 seconds.\n",
      "Records by worker (~50 worker sample): 0:10037 1:9718 2:10096 3:10193 4:10232 5:10013 6:9923 7:9674 8:9991 9:10123 \n",
      "\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 6 seconds.\n",
      "Records by worker (~50 worker sample): 0:882 2:973 4:989 6:1090 8:950 10:1029 12:883 14:1001 16:1091 18:1023 20:999 22:937 24:969 26:966 28:925 30:1065 32:961 34:981 36:919 38:1052 40:1090 42:960 44:1001 46:927 48:950 50:1063 52:1115 54:905 56:1003 58:978 60:927 62:1108 64:1001 66:1153 68:1114 70:1035 72:1090 74:983 76:994 78:1042 80:954 82:1010 84:1050 86:940 88:923 90:1025 92:1061 94:993 96:1034 98:1013 \n",
      "\n",
      "1000 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 6 seconds.\n",
      "Records by worker (~50 worker sample): 0:148 20:98 40:113 60:98 80:147 100:105 120:99 140:92 160:113 180:126 200:82 220:88 240:88 260:131 280:70 300:96 320:131 340:132 360:122 380:112 400:99 420:107 440:104 460:98 480:122 500:91 520:91 540:86 560:105 580:85 600:91 620:87 640:72 660:57 680:74 700:83 720:105 740:96 760:112 780:104 800:67 820:85 840:65 860:103 880:93 900:138 920:112 940:108 960:149 980:72 \n",
      "\n",
      "5000 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 10 seconds.\n",
      "Records by worker (~50 worker sample): 0:23 100:64 200:26 300:42 400:18 500:48 600:43 700:26 800:56 900:66 1000:44 1100:47 1200:40 1300:24 1400:23 1500:16 1600:24 1700:9 1800:15 1900:72 2000:7 2100:19 2200:33 2300:37 2400:9 2500:9 2600:11 2700:14 2800:4 2900:12 3000:10 3100:14 3200:6 3300:12 3400:5 3500:21 3600:11 3700:11 3800:9 3900:18 4000:8 4100:19 4200:15 4300:12 4400:14 4500:6 4600:5 4700:41 4800:24 4900:0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "int reqSplits = 10000;\n",
    "\n",
    "SplitAssignment[] splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, 10);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, 100);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, 1000);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, 5000);\n",
    "workerSummary();\n",
    "System.out.println();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying number of workers in sync and async mode\n",
    "Vary the number of workers from 10 to 5000 in sync and async mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mode: SYNC\n",
      "Split type EXACT_NUM_SPLITS, requested 10000, assigned 10000 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 1, sub_start: 0, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 0, ptn_count: 1, sub_start: 4096, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 5000:\n",
      "\t\tptn_start: 2048, ptn_count: 1, sub_start: 0, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 9998:\n",
      "\t\tptn_start: 4095, ptn_count: 1, sub_start: 1808, sub_count: 4096, sub_mod: 10000\n",
      "\tSplit 9999:\n",
      "\t\tptn_start: 4095, ptn_count: 1, sub_start: 5904, sub_count: 4096, sub_mod: 10000\n",
      "10 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 5 seconds.\n",
      "Records by worker (~50 worker sample): 0:10031 1:10153 2:9838 3:9816 4:9852 5:10097 6:9922 7:10032 8:10022 9:10237 \n",
      "\n",
      "Processing mode: ASYNC\n",
      "10 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 4 seconds.\n",
      "Records by worker (~50 worker sample): 0:10112 1:10082 2:9734 3:10029 4:9757 5:10370 6:10125 7:9925 8:9878 9:9988 \n",
      "\n",
      "Processing mode: SYNC\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 5 seconds.\n",
      "Records by worker (~50 worker sample): 0:1537 2:1355 4:1420 6:1384 8:1472 10:1509 12:1048 14:792 16:856 18:757 20:821 22:812 24:798 26:825 28:892 30:816 32:827 34:870 36:828 38:913 40:841 42:826 44:884 46:917 48:860 50:1018 52:787 54:904 56:955 58:917 60:980 62:991 64:852 66:1017 68:1030 70:949 72:999 74:972 76:1106 78:1532 80:1009 82:1220 84:1079 86:1175 88:982 90:1073 92:1088 94:1124 96:1123 98:1355 \n",
      "\n",
      "Processing mode: ASYNC\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 3 seconds.\n",
      "Records by worker (~50 worker sample): 0:924 2:1079 4:936 6:1025 8:869 10:1166 12:1115 14:895 16:948 18:1129 20:962 22:1053 24:922 26:964 28:993 30:850 32:1018 34:1016 36:1122 38:1095 40:1015 42:917 44:1027 46:1024 48:902 50:953 52:1006 54:1130 56:986 58:1012 60:1093 62:909 64:984 66:1023 68:1045 70:1066 72:1043 74:1058 76:937 78:935 80:1008 82:967 84:1042 86:897 88:960 90:1089 92:1034 94:1014 96:971 98:1018 \n",
      "\n",
      "Processing mode: SYNC\n",
      "1000 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 5 seconds.\n",
      "Records by worker (~50 worker sample): 0:124 20:74 40:80 60:241 80:297 100:150 120:101 140:219 160:137 180:104 200:106 220:54 240:163 260:56 280:92 300:151 320:145 340:141 360:271 380:220 400:178 420:206 440:47 460:56 480:69 500:74 520:70 540:73 560:78 580:71 600:39 620:42 640:58 660:62 680:62 700:47 720:243 740:25 760:59 780:44 800:52 820:42 840:46 860:56 880:55 900:64 920:77 940:111 960:60 980:87 \n",
      "\n",
      "Processing mode: ASYNC\n",
      "1000 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 3 seconds.\n",
      "Records by worker (~50 worker sample): 0:113 20:127 40:116 60:133 80:98 100:92 120:103 140:109 160:114 180:118 200:89 220:138 240:128 260:54 280:86 300:103 320:77 340:148 360:132 380:93 400:94 420:115 440:73 460:85 480:110 500:51 520:131 540:125 560:81 580:105 600:125 620:115 640:103 660:90 680:102 700:135 720:42 740:106 760:53 780:99 800:134 820:92 840:107 860:150 880:89 900:134 920:168 940:82 960:76 980:88 \n",
      "\n",
      "Processing mode: SYNC\n",
      "5000 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 11 seconds.\n",
      "Records by worker (~50 worker sample): 0:62 100:19 200:14 300:31 400:18 500:36 600:49 700:56 800:41 900:12 1000:27 1100:33 1200:33 1300:13 1400:8 1500:12 1600:21 1700:11 1800:14 1900:28 2000:27 2100:27 2200:14 2300:32 2400:7 2500:14 2600:5 2700:8 2800:6 2900:10 3000:8 3100:15 3200:58 3300:11 3400:10 3500:10 3600:10 3700:8 3800:8 3900:19 4000:14 4100:5 4200:28 4300:9 4400:10 4500:26 4600:13 4700:37 4800:26 4900:15 \n",
      "\n",
      "Processing mode: ASYNC\n",
      "5000 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 6 seconds.\n",
      "Records by worker (~50 worker sample): 0:58 100:10 200:15 300:34 400:32 500:12 600:41 700:21 800:36 900:15 1000:25 1100:13 1200:6 1300:11 1400:19 1500:12 1600:8 1700:29 1800:32 1900:18 2000:16 2100:21 2200:13 2300:21 2400:13 2500:21 2600:18 2700:20 2800:23 2900:22 3000:10 3100:11 3200:11 3300:23 3400:26 3500:8 3600:16 3700:17 3800:18 3900:8 4000:7 4100:38 4200:23 4300:7 4400:34 4500:7 4600:8 4700:18 4800:10 4900:21 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "int reqSplits = 10000;\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_SYNC;\n",
    "System.out.format(\"Processing mode: SYNC\\n\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, 10);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_ASYNC;\n",
    "System.out.format(\"Processing mode: ASYNC\\n\");\n",
    "splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, 10);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_SYNC;\n",
    "System.out.format(\"Processing mode: SYNC\\n\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, 100);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_ASYNC;\n",
    "System.out.format(\"Processing mode: ASYNC\\n\");\n",
    "splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, 100);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_SYNC;\n",
    "System.out.format(\"Processing mode: SYNC\\n\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, 1000);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_ASYNC;\n",
    "System.out.format(\"Processing mode: ASYNC\\n\");\n",
    "splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, 1000);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_SYNC;\n",
    "System.out.format(\"Processing mode: SYNC\\n\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, 5000);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ProcessingMode = PROCESSING_MODE_ASYNC;\n",
    "System.out.format(\"Processing mode: ASYNC\\n\");\n",
    "splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, 5000);\n",
    "workerSummary();\n",
    "System.out.println();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying query type and filter\n",
    "Primary-index and sexondary-index queries with and without a filter expression. Note the default secondary-index query predicate will process half the records and yield half the sum value. The default filter expression, in turn, will also process half the records and yield half the sum of the filterless query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary-index query with no filter\n",
      "Split type EXACT_NUM_SPLITS, requested 1000, assigned 1000 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 4, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 4, ptn_count: 1, sub_start: 0, sub_count: 96, sub_mod: 1000\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 4, ptn_count: 1, sub_start: 96, sub_count: 904, sub_mod: 1000\n",
      "\t\tptn_start: 5, ptn_count: 3, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 8, ptn_count: 1, sub_start: 0, sub_count: 192, sub_mod: 1000\n",
      "\tSplit 500:\n",
      "\t\tptn_start: 2048, ptn_count: 4, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 2052, ptn_count: 1, sub_start: 0, sub_count: 96, sub_mod: 1000\n",
      "\tSplit 998:\n",
      "\t\tptn_start: 4087, ptn_count: 1, sub_start: 808, sub_count: 192, sub_mod: 1000\n",
      "\t\tptn_start: 4088, ptn_count: 3, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 4091, ptn_count: 1, sub_start: 0, sub_count: 904, sub_mod: 1000\n",
      "\tSplit 999:\n",
      "\t\tptn_start: 4091, ptn_count: 1, sub_start: 904, sub_count: 96, sub_mod: 1000\n",
      "\t\tptn_start: 4092, ptn_count: 4, sub_start: null, sub_count: null, sub_mod: null\n",
      "10 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 2 seconds.\n",
      "Records by worker (~50 worker sample): 0:9761 1:9662 2:10238 3:10074 4:9921 5:10233 6:9942 7:9999 8:9989 9:10181 \n",
      "\n",
      "Primary-index query with filter expression\n",
      "10 worker threads.\n",
      "Record count is 50000, sum is 2500050000.\n",
      "That took 2 seconds.\n",
      "\n",
      "Secondary-index query with no filter\n",
      "10 worker threads.\n",
      "Record count is 50000, sum is 2500025000.\n",
      "That took 1 seconds.\n",
      "\n",
      "Secondary-index query with filter expression\n",
      "10 worker threads.\n",
      "Record count is 25000, sum is 1250025000.\n",
      "That took 1 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// the following filter expression chooses records with even values of bin1 - CAN CHANGE TO A DIFFERENT EXPRESSION\n",
    "//    used when QueryFilter = QUERY_FILTER_INCLUDE\n",
    "IncludeQueryFilterExp = Exp.eq(Exp.mod(Exp.intBin(\"bin1\"), Exp.val(2)), Exp.val(0));\n",
    "\n",
    "// the following query predicate is a range filter for records with 50001 <= bin1 <= 100000 - CAN CHANGE TO A DIFFERENT QUERY PREDICATE\n",
    "//    used when QueryType = SECONDARY_INDEX_QUERY\n",
    "SecondaryIndexQueryPredicate = Filter.range(\"bin1\", 25001, 75000);\n",
    "\n",
    "int reqSplits = 1000;\n",
    "//int NumWorkers = 100;\n",
    "int NumWorkers = 10;\n",
    "ProcessingMode = PROCESSING_MODE_SYNC;\n",
    "\n",
    "QueryType = PRIMARY_INDEX_QUERY;\n",
    "QueryFilter = QUERY_FILTER_NONE;\n",
    "System.out.format(\"Primary-index query with no filter\\n\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "QueryType = PRIMARY_INDEX_QUERY;\n",
    "QueryFilter = QUERY_FILTER_INCLUDE;\n",
    "System.out.format(\"Primary-index query with filter expression\\n\");\n",
    "splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "//workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "QueryType = SECONDARY_INDEX_QUERY;\n",
    "QueryFilter = QUERY_FILTER_NONE;\n",
    "System.out.format(\"Secondary-index query with no filter\\n\");\n",
    "splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "//workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "QueryType = SECONDARY_INDEX_QUERY;\n",
    "QueryFilter = QUERY_FILTER_INCLUDE;\n",
    "System.out.format(\"Secondary-index query with filter expression\\n\");\n",
    "splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, NumWorkers);\n",
    "//workerSummary();\n",
    "System.out.println();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying max-records chunk size\n",
    "Vary the chunk size from 10 to 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-records chunk size: 10\n",
      "Split type EXACT_NUM_SPLITS, requested 100, assigned 100 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 40, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 40, ptn_count: 1, sub_start: 0, sub_count: 96, sub_mod: 100\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 40, ptn_count: 1, sub_start: 96, sub_count: 4, sub_mod: 100\n",
      "\t\tptn_start: 41, ptn_count: 40, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 81, ptn_count: 1, sub_start: 0, sub_count: 92, sub_mod: 100\n",
      "\tSplit 50:\n",
      "\t\tptn_start: 2048, ptn_count: 40, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 2088, ptn_count: 1, sub_start: 0, sub_count: 96, sub_mod: 100\n",
      "\tSplit 98:\n",
      "\t\tptn_start: 4014, ptn_count: 1, sub_start: 8, sub_count: 92, sub_mod: 100\n",
      "\t\tptn_start: 4015, ptn_count: 40, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 4055, ptn_count: 1, sub_start: 0, sub_count: 4, sub_mod: 100\n",
      "\tSplit 99:\n",
      "\t\tptn_start: 4055, ptn_count: 1, sub_start: 4, sub_count: 96, sub_mod: 100\n",
      "\t\tptn_start: 4056, ptn_count: 40, sub_start: null, sub_count: null, sub_mod: null\n",
      "50 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 4 seconds.\n",
      "Records by worker (~50 worker sample): 0:1985 1:1983 2:2077 3:2030 4:2001 5:1960 6:2048 7:1983 8:1946 9:1989 10:2064 11:1980 12:2019 13:1934 14:1960 15:1962 16:1978 17:1914 18:2059 19:1965 20:2080 21:2042 22:2013 23:1976 24:2044 25:2001 26:2049 27:2038 28:1994 29:2013 30:2068 31:2017 32:1965 33:2048 34:2023 35:1930 36:2009 37:2036 38:1979 39:1904 40:1913 41:1981 42:2042 43:2087 44:2002 45:1973 46:2102 47:1936 48:1898 49:2000 \n",
      "\n",
      "Max-records chunk size: 25\n",
      "50 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 2 seconds.\n",
      "\n",
      "Max-records chunk size: 100\n",
      "50 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 0 seconds.\n",
      "\n",
      "Max-records chunk size: 300\n",
      "50 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 0 seconds.\n",
      "\n",
      "Max-records chunk size: 500\n",
      "50 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 0 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "int reqSplits = 100;\n",
    "int numWorkers = 50;\n",
    "ProcessingMode = PROCESSING_MODE_ASYNC;\n",
    "QueryType = PRIMARY_INDEX_QUERY;\n",
    "QueryFilter = QUERY_FILTER_NONE;\n",
    "\n",
    "ChunkSize = 10;\n",
    "System.out.format(\"Max-records chunk size: %d\\n\", ChunkSize);\n",
    "splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ChunkSize = 25;\n",
    "System.out.format(\"Max-records chunk size: %d\\n\", ChunkSize);\n",
    "splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "//workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ChunkSize = 100;\n",
    "System.out.format(\"Max-records chunk size: %d\\n\", ChunkSize);\n",
    "splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "//workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ChunkSize = 300;\n",
    "System.out.format(\"Max-records chunk size: %d\\n\", ChunkSize);\n",
    "splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "//workerSummary();\n",
    "System.out.println();\n",
    "\n",
    "ChunkSize = 500;\n",
    "System.out.format(\"Max-records chunk size: %d\\n\", ChunkSize);\n",
    "splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "//workerSummary();\n",
    "System.out.println();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition Slices: A New Split Assignment Scheme\n",
    "To illustrate how to define an new split assignment scheme, let us define a simple variation of exact number of splits, in which each partition is divided into as many subpartitions as the desired number of splits. Each split is assigned one slice (subpartition) from each of the 4096 partitions.\n",
    "\n",
    "The following cell defines the function for such a split assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SplitAssignment[] assignExactSplitsSliced(int reqSplits) {\n",
    "    SplitAssignment[] assignments = new SplitAssignment[reqSplits];\n",
    "    for (int i=0; i < reqSplits; i++) {\n",
    "        QueryPartition qp = new QueryPartition(0, 4096, reqSplits, i, 1); // one slice from all 4096 partitions\n",
    "        assignments[i] = new SplitAssignment(qp);        \n",
    "    }\n",
    "    return assignments;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now compare the new scheme with the EXACT_NUM_SPLITS scheme defined earlier. Below, we run the two schemes with diffrent number of splits and chunk sizes.\n",
    "\n",
    "You will notice that with a smaller chunk size and finer slices, the performance of partition-slices deteirorates. Even with non chunked retrieval, its performance is worse than the vertical assignment. \n",
    "\n",
    "You can also customize the test framework to suit your needs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size: 200\n",
      "Requested splits: 10, type: EXACT_NUM_SPLITS\n",
      "Split type EXACT_NUM_SPLITS, requested 100, assigned 10 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 409, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 409, ptn_count: 1, sub_start: 0, sub_count: 6, sub_mod: 10\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 409, ptn_count: 1, sub_start: 6, sub_count: 4, sub_mod: 10\n",
      "\t\tptn_start: 410, ptn_count: 409, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 819, ptn_count: 1, sub_start: 0, sub_count: 2, sub_mod: 10\n",
      "\tSplit 5:\n",
      "\t\tptn_start: 2048, ptn_count: 409, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 2457, ptn_count: 1, sub_start: 0, sub_count: 6, sub_mod: 10\n",
      "\tSplit 8:\n",
      "\t\tptn_start: 3276, ptn_count: 1, sub_start: 8, sub_count: 2, sub_mod: 10\n",
      "\t\tptn_start: 3277, ptn_count: 409, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 3686, ptn_count: 1, sub_start: 0, sub_count: 4, sub_mod: 10\n",
      "\tSplit 9:\n",
      "\t\tptn_start: 3686, ptn_count: 1, sub_start: 4, sub_count: 6, sub_mod: 10\n",
      "\t\tptn_start: 3687, ptn_count: 409, sub_start: null, sub_count: null, sub_mod: null\n",
      "10 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 0 seconds.\n",
      "\n",
      "Requested splits: 10, type: PARTITION_SLICES\n",
      "10 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 13 seconds.\n",
      "\n",
      "Requested splits: 100, type: EXACT_NUM_SPLITS\n",
      "10 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 0 seconds.\n",
      "\n",
      "Requested splits: 100, type: PARTITION_SLICES\n",
      "10 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 51 seconds.\n",
      "\n",
      "Chunk size: 1000000\n",
      "Requested splits: 10, type: EXACT_NUM_SPLITS\n",
      "10 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 0 seconds.\n",
      "\n",
      "Requested splits: 10, type: PARTITION_SLICES\n",
      "10 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 3 seconds.\n",
      "\n",
      "Requested splits: 100, type: EXACT_NUM_SPLITS\n",
      "10 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 0 seconds.\n",
      "\n",
      "Requested splits: 100, type: PARTITION_SLICES\n",
      "10 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 35 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "int numWorkers = 10;\n",
    "\n",
    "System.out.println(\"Chunk size: 200\");\n",
    "ChunkSize = 1000;\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 10, \"EXACT_NUM_SPLITS\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(10, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 10, \"PARTITION_SLICES\");\n",
    "SplitAssignment[] splitAssignments = assignExactSplitsSliced(10);\n",
    "assignmentSummary(\"PARTITION_SLICES\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 100, \"EXACT_NUM_SPLITS\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(100, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 100, \"PARTITION_SLICES\");\n",
    "SplitAssignment[] splitAssignments = assignExactSplitsSliced(100);\n",
    "assignmentSummary(\"PARTITION_SLICES\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n",
    "\n",
    "// with unlimited chunk size\n",
    "System.out.println(\"Chunk size: 1000000\");\n",
    "ChunkSize = 1000000;\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 10, \"EXACT_NUM_SPLITS\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(10, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 10, \"PARTITION_SLICES\");\n",
    "SplitAssignment[] splitAssignments = assignExactSplitsSliced(10);\n",
    "//assignmentSummary(\"PARTITION_SLICES\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 100, \"EXACT_NUM_SPLITS\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(100, EXACT_NUM_SPLITS);\n",
    "//assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n",
    "\n",
    "System.out.format(\"Requested splits: %d, type: %s\\n\", 100, \"PARTITION_SLICES\");\n",
    "SplitAssignment[] splitAssignments = assignExactSplitsSliced(100);\n",
    "//assignmentSummary(\"PARTITION_SLICES\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "System.out.println();\n",
    "\n",
    "// reset\n",
    "ChunkSize = 20;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and run with your own parameters\n",
    "Experiment with the values in the following cell and see what results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with parameter values (specify)\n",
      "Split type EXACT_NUM_SPLITS, requested 1000, assigned 1000 (ends and middle): \n",
      "\tSplit 0:\n",
      "\t\tptn_start: 0, ptn_count: 4, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 4, ptn_count: 1, sub_start: 0, sub_count: 96, sub_mod: 1000\n",
      "\tSplit 1:\n",
      "\t\tptn_start: 4, ptn_count: 1, sub_start: 96, sub_count: 904, sub_mod: 1000\n",
      "\t\tptn_start: 5, ptn_count: 3, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 8, ptn_count: 1, sub_start: 0, sub_count: 192, sub_mod: 1000\n",
      "\tSplit 500:\n",
      "\t\tptn_start: 2048, ptn_count: 4, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 2052, ptn_count: 1, sub_start: 0, sub_count: 96, sub_mod: 1000\n",
      "\tSplit 998:\n",
      "\t\tptn_start: 4087, ptn_count: 1, sub_start: 808, sub_count: 192, sub_mod: 1000\n",
      "\t\tptn_start: 4088, ptn_count: 3, sub_start: null, sub_count: null, sub_mod: null\n",
      "\t\tptn_start: 4091, ptn_count: 1, sub_start: 0, sub_count: 904, sub_mod: 1000\n",
      "\tSplit 999:\n",
      "\t\tptn_start: 4091, ptn_count: 1, sub_start: 904, sub_count: 96, sub_mod: 1000\n",
      "\t\tptn_start: 4092, ptn_count: 4, sub_start: null, sub_count: null, sub_mod: null\n",
      "100 worker threads.\n",
      "Record count is 100000, sum is 5000050000.\n",
      "That took 2 seconds.\n",
      "Records by worker (~50 worker sample): 0:3319 2:789 4:786 6:699 8:695 10:666 12:801 14:781 16:1194 18:899 20:828 22:765 24:950 26:958 28:1009 30:865 32:530 34:1243 36:1085 38:1097 40:1188 42:1353 44:1620 46:2031 48:2511 50:2534 52:2942 54:2865 56:621 58:571 60:673 62:606 64:594 66:705 68:663 70:588 72:619 74:668 76:598 78:1145 80:617 82:706 84:685 86:603 88:697 90:701 92:663 94:697 96:742 98:497 \n"
     ]
    }
   ],
   "source": [
    "ProcessingMode = PROCESSING_MODE_SYNC;\n",
    "QueryType = PRIMARY_INDEX_QUERY;\n",
    "QueryFilter = QUERY_FILTER_NONE;\n",
    "ChunkSize = 20;\n",
    "\n",
    "// the following filter expression chooses records with even values of bin1 - CAN CHANGE TO A DIFFERENT EXPRESSION\n",
    "//    used when QueryFilter = QUERY_FILTER_INCLUDE\n",
    "IncludeQueryFilterExp = Exp.eq(Exp.mod(Exp.intBin(\"bin1\"), Exp.val(2)), Exp.val(0));\n",
    "\n",
    "// the following query predicate is a range filter for records with 50001 <= bin1 <= 100000 - CAN CHANGE TO A DIFFERENT QUERY PREDICATE\n",
    "//    used when QueryType = SECONDARY_INDEX_QUERY\n",
    "SecondaryIndexQueryPredicate = Filter.range(\"bin1\", 50001, 100000);\n",
    "\n",
    "int reqSplits = 1000;\n",
    "int SplitType = EXACT_NUM_SPLITS;\n",
    "int numWorkers = 100;\n",
    "\n",
    "System.out.format(\"Running with parameter values (specify)\\n\");\n",
    "SplitAssignment[] splitAssignments = assignSplits(reqSplits, EXACT_NUM_SPLITS);\n",
    "assignmentSummary(\"EXACT_NUM_SPLITS\", reqSplits, splitAssignments);\n",
    "processSplits(splitAssignments, numWorkers);\n",
    "workerSummary();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways and Conclusion\n",
    "The ability to retrieve a large data set in parallel streams for processing in a large number of workers is essential to high throughput applications. Aerospike provides mechanisms to divide a large data set over an arbitrary number of splits and process each split in smaller chunks at a time. The notebook implements mulriple schemes for split assignments, and provides a framework for parallel processing a query over splits. It also demonstrates parallel processing using varying values of splits, workers, query and filter, chunk size, and processing mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Exploration and Resources\n",
    "Here are some links for further exploration\n",
    "\n",
    "Resources\n",
    "- [Processing Large Data Sets with Fine Grained Streams](https://developer.aerospike.com/blog/fine-grained-streams) (blog post)\n",
    "- [Aerospike Developer Hub](https://developer.aerospike.com)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.8+10-LTS"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
